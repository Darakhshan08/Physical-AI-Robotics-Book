{"allContent":{"docusaurus-plugin-content-docs":{"default":{"loadedVersions":[{"versionName":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","path":"/docs","tagsPath":"/docs/tags","editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs","isLast":true,"routePriority":-1,"sidebarFilePath":"D:\\D\\Gov\\4rth_semester\\pro\\4rth\\Heckathon-Book\\sidebars.js","contentPath":"D:\\D\\Gov\\4rth_semester\\pro\\4rth\\Heckathon-Book\\docs","docs":[{"id":"appendices/cloud-setup","title":"Cloud Lab Setup","description":"AWS RoboMaker setup, NVIDIA Omniverse Cloud, Cost optimization, Remote development workflow.","source":"@site/docs/appendices/cloud-setup.mdx","sourceDirName":"appendices","slug":"/appendices/cloud-setup","permalink":"/docs/appendices/cloud-setup","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/appendices/cloud-setup.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"cloud-setup","title":"Cloud Lab Setup","sidebar_label":"Cloud Lab Setup","sidebar_position":2,"description":"AWS RoboMaker setup, NVIDIA Omniverse Cloud, Cost optimization, Remote development workflow.","keywords":["cloud","aws","robomaker","omniverse-cloud","remote-development"]},"sidebar":"tutorialSidebar","previous":{"title":"Hardware Setup","permalink":"/docs/appendices/hardware-setup"},"next":{"title":"Troubleshooting","permalink":"/docs/appendices/troubleshooting"}},{"id":"appendices/glossary","title":"Glossary of Terms","description":"100+ robotics and AI terms, Alphabetical listing.","source":"@site/docs/appendices/glossary.mdx","sourceDirName":"appendices","slug":"/appendices/glossary","permalink":"/docs/appendices/glossary","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/appendices/glossary.mdx","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"glossary","title":"Glossary of Terms","sidebar_label":"Glossary","sidebar_position":4,"description":"100+ robotics and AI terms, Alphabetical listing.","keywords":["glossary","robotics-terms","ai-terms"]},"sidebar":"tutorialSidebar","previous":{"title":"Troubleshooting","permalink":"/docs/appendices/troubleshooting"},"next":{"title":"Resources","permalink":"/docs/appendices/resources"}},{"id":"appendices/hardware-setup","title":"Hardware Setup Guides","description":"Jetson Orin Nano complete setup, Intel RealSense D435i configuration, ReSpeaker microphone setup, Unitree Go2/G1 SDK, Network configuration.","source":"@site/docs/appendices/hardware-setup.mdx","sourceDirName":"appendices","slug":"/appendices/hardware-setup","permalink":"/docs/appendices/hardware-setup","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/appendices/hardware-setup.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"hardware-setup","title":"Hardware Setup Guides","sidebar_label":"Hardware Setup","sidebar_position":1,"description":"Jetson Orin Nano complete setup, Intel RealSense D435i configuration, ReSpeaker microphone setup, Unitree Go2/G1 SDK, Network configuration.","keywords":["hardware","setup","jetson-orin-nano","realsense","unitree","ros2"]},"sidebar":"tutorialSidebar","previous":{"title":"Appendices","permalink":"/docs/category/appendices"},"next":{"title":"Cloud Lab Setup","permalink":"/docs/appendices/cloud-setup"}},{"id":"appendices/resources","title":"Additional Resources","description":"Official documentation links, Recommended courses, Research papers, Community resources, GitHub repositories.","source":"@site/docs/appendices/resources.mdx","sourceDirName":"appendices","slug":"/appendices/resources","permalink":"/docs/appendices/resources","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/appendices/resources.mdx","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"id":"resources","title":"Additional Resources","sidebar_label":"Resources","sidebar_position":5,"description":"Official documentation links, Recommended courses, Research papers, Community resources, GitHub repositories.","keywords":["resources","ros2","gazebo","isaac-sim","openai","robotics"]},"sidebar":"tutorialSidebar","previous":{"title":"Glossary","permalink":"/docs/appendices/glossary"},"next":{"title":"What is Physical AI?","permalink":"/docs/intro/what-is-physical-ai"}},{"id":"appendices/troubleshooting","title":"Troubleshooting Common Issues","description":"ROS 2 errors and fixes, Gazebo crashes, Isaac Sim GPU issues, Network problems, Build failures.","source":"@site/docs/appendices/troubleshooting.mdx","sourceDirName":"appendices","slug":"/appendices/troubleshooting","permalink":"/docs/appendices/troubleshooting","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/appendices/troubleshooting.mdx","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"troubleshooting","title":"Troubleshooting Common Issues","sidebar_label":"Troubleshooting","sidebar_position":3,"description":"ROS 2 errors and fixes, Gazebo crashes, Isaac Sim GPU issues, Network problems, Build failures.","keywords":["troubleshooting","ros2","gazebo","isaac-sim","network","build"]},"sidebar":"tutorialSidebar","previous":{"title":"Cloud Lab Setup","permalink":"/docs/appendices/cloud-setup"},"next":{"title":"Glossary","permalink":"/docs/appendices/glossary"}},{"id":"capstone/capstone-architecture","title":"System Architecture Design","description":"Node graph design, Topic/service mapping, Launch organization, Configuration management, Logging and debugging, Testing strategy.","source":"@site/docs/capstone/architecture.mdx","sourceDirName":"capstone","slug":"/capstone/capstone-architecture","permalink":"/docs/capstone/capstone-architecture","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/capstone/architecture.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"capstone-architecture","title":"System Architecture Design","sidebar_label":"Architecture Design","sidebar_position":2,"description":"Node graph design, Topic/service mapping, Launch organization, Configuration management, Logging and debugging, Testing strategy.","keywords":["capstone","architecture","ros2","nodes","topics","launch-files"]},"sidebar":"tutorialSidebar","previous":{"title":"Project Overview","permalink":"/docs/capstone/capstone-overview"},"next":{"title":"Voice Pipeline","permalink":"/docs/capstone/voice-pipeline"}},{"id":"capstone/capstone-deployment","title":"Deployment and Demo","description":"Sim-to-real checklist, Jetson deployment, Real robot config, Demo preparation, Recording and documentation, Future improvements.","source":"@site/docs/capstone/deployment.mdx","sourceDirName":"capstone","slug":"/capstone/capstone-deployment","permalink":"/docs/capstone/capstone-deployment","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/capstone/deployment.mdx","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"id":"capstone-deployment","title":"Deployment and Demo","sidebar_label":"Deployment & Demo","sidebar_position":7,"description":"Sim-to-real checklist, Jetson deployment, Real robot config, Demo preparation, Recording and documentation, Future improvements.","keywords":["capstone","deployment","demo","sim-to-real","jetson","robotics"]},"sidebar":"tutorialSidebar","previous":{"title":"Integration & Testing","permalink":"/docs/capstone/capstone-integration"},"next":{"title":"Appendices","permalink":"/docs/category/appendices"}},{"id":"capstone/capstone-integration","title":"Integration and Testing","description":"System integration steps, Unit testing nodes, Integration testing, Simulation checklist, Performance profiling, Bug tracking.","source":"@site/docs/capstone/integration.mdx","sourceDirName":"capstone","slug":"/capstone/capstone-integration","permalink":"/docs/capstone/capstone-integration","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/capstone/integration.mdx","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"id":"capstone-integration","title":"Integration and Testing","sidebar_label":"Integration & Testing","sidebar_position":6,"description":"System integration steps, Unit testing nodes, Integration testing, Simulation checklist, Performance profiling, Bug tracking.","keywords":["capstone","integration","testing","unit-tests","ros2","simulation"]},"sidebar":"tutorialSidebar","previous":{"title":"Manipulation","permalink":"/docs/capstone/capstone-manipulation"},"next":{"title":"Deployment & Demo","permalink":"/docs/capstone/capstone-deployment"}},{"id":"capstone/capstone-manipulation","title":"Object Detection and Manipulation","description":"Object detection model, Target localization, Approach planning, Grasp execution, Manipulation feedback, Error recovery.","source":"@site/docs/capstone/manipulation.mdx","sourceDirName":"capstone","slug":"/capstone/capstone-manipulation","permalink":"/docs/capstone/capstone-manipulation","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/capstone/manipulation.mdx","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"id":"capstone-manipulation","title":"Object Detection and Manipulation","sidebar_label":"Manipulation","sidebar_position":5,"description":"Object detection model, Target localization, Approach planning, Grasp execution, Manipulation feedback, Error recovery.","keywords":["capstone","object-detection","manipulation","grasping","ros2"]},"sidebar":"tutorialSidebar","previous":{"title":"Navigation","permalink":"/docs/capstone/capstone-navigation"},"next":{"title":"Integration & Testing","permalink":"/docs/capstone/capstone-integration"}},{"id":"capstone/capstone-navigation","title":"Path Planning and Navigation","description":"Environment mapping, Goal pose from commands, Nav2 integration, Obstacle avoidance, Recovery behaviors, Navigation monitoring.","source":"@site/docs/capstone/navigation.mdx","sourceDirName":"capstone","slug":"/capstone/capstone-navigation","permalink":"/docs/capstone/capstone-navigation","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/capstone/navigation.mdx","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"capstone-navigation","title":"Path Planning and Navigation","sidebar_label":"Navigation","sidebar_position":4,"description":"Environment mapping, Goal pose from commands, Nav2 integration, Obstacle avoidance, Recovery behaviors, Navigation monitoring.","keywords":["capstone","navigation","nav2","mapping","path-planning","obstacle-avoidance"]},"sidebar":"tutorialSidebar","previous":{"title":"Voice Pipeline","permalink":"/docs/capstone/voice-pipeline"},"next":{"title":"Manipulation","permalink":"/docs/capstone/capstone-manipulation"}},{"id":"capstone/capstone-overview","title":"Capstone Project Overview","description":"Capstone requirements, System architecture, Success criteria, Milestone breakdown, Assessment rubric.","source":"@site/docs/capstone/overview.mdx","sourceDirName":"capstone","slug":"/capstone/capstone-overview","permalink":"/docs/capstone/capstone-overview","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/capstone/overview.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"capstone-overview","title":"Capstone Project Overview","sidebar_label":"Project Overview","sidebar_position":1,"description":"Capstone requirements, System architecture, Success criteria, Milestone breakdown, Assessment rubric.","keywords":["capstone","project-overview","humanoid","robotics","ai"]},"sidebar":"tutorialSidebar","previous":{"title":"Part 5: Capstone Project","permalink":"/docs/category/part-5-capstone-project"},"next":{"title":"Architecture Design","permalink":"/docs/capstone/capstone-architecture"}},{"id":"capstone/voice-pipeline","title":"Voice Command Processing Pipeline","description":"Microphone input, Whisper integration, Command classification, Intent extraction, ROS 2 action triggering, User feedback.","source":"@site/docs/capstone/voice-pipeline.mdx","sourceDirName":"capstone","slug":"/capstone/voice-pipeline","permalink":"/docs/capstone/voice-pipeline","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/capstone/voice-pipeline.mdx","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"voice-pipeline","title":"Voice Command Processing Pipeline","sidebar_label":"Voice Pipeline","sidebar_position":3,"description":"Microphone input, Whisper integration, Command classification, Intent extraction, ROS 2 action triggering, User feedback.","keywords":["voice-command","whisper","ros2","intent-extraction","nlp"]},"sidebar":"tutorialSidebar","previous":{"title":"Architecture Design","permalink":"/docs/capstone/capstone-architecture"},"next":{"title":"Navigation","permalink":"/docs/capstone/capstone-navigation"}},{"id":"intro/course-overview","title":"Course Overview & Hardware Requirements","description":"13-week course breakdown, Hardware Tier 1, 2, 3 requirements, Cloud alternative, pricing tables.","source":"@site/docs/intro/course-overview.mdx","sourceDirName":"intro","slug":"/intro/course-overview","permalink":"/docs/intro/course-overview","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/intro/course-overview.mdx","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"course-overview","title":"Course Overview & Hardware Requirements","sidebar_label":"Course Overview","sidebar_position":3,"description":"13-week course breakdown, Hardware Tier 1, 2, 3 requirements, Cloud alternative, pricing tables.","keywords":["course-overview","hardware-requirements","jetson-orin-nano","realsense","unitree","aws"]},"sidebar":"tutorialSidebar","previous":{"title":"Why Humanoid Robots?","permalink":"/docs/intro/why-humanoid-robots"},"next":{"title":"Environment Setup","permalink":"/docs/intro/environment-setup"}},{"id":"intro/environment-setup","title":"Environment Setup","description":"Ubuntu 22.04 LTS installation, ROS 2 Humble installation, Gazebo Harmonic setup, NVIDIA Isaac Sim (Omniverse) installation, Python venv and dependencies, VS Code configuration, Verification commands.","source":"@site/docs/intro/environment-setup.mdx","sourceDirName":"intro","slug":"/intro/environment-setup","permalink":"/docs/intro/environment-setup","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/intro/environment-setup.mdx","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"environment-setup","title":"Environment Setup","sidebar_label":"Environment Setup","sidebar_position":4,"description":"Ubuntu 22.04 LTS installation, ROS 2 Humble installation, Gazebo Harmonic setup, NVIDIA Isaac Sim (Omniverse) installation, Python venv and dependencies, VS Code configuration, Verification commands.","keywords":["environment-setup","ubuntu","ros2","gazebo","isaac-sim","python","vscode"]},"sidebar":"tutorialSidebar","previous":{"title":"Course Overview","permalink":"/docs/intro/course-overview"}},{"id":"intro/what-is-physical-ai","title":"What is Physical AI?","description":"Digital AI vs Embodied AI differences, Physical AI definition and core concepts, Real-world applications, Why robots need to understand physics.","source":"@site/docs/intro/what-is-physical-ai.mdx","sourceDirName":"intro","slug":"/intro/what-is-physical-ai","permalink":"/docs/intro/what-is-physical-ai","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/intro/what-is-physical-ai.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"what-is-physical-ai","title":"What is Physical AI?","sidebar_label":"What is Physical AI?","sidebar_position":1,"description":"Digital AI vs Embodied AI differences, Physical AI definition and core concepts, Real-world applications, Why robots need to understand physics.","keywords":["physical-ai","embodied-ai","robotics","ai","physics"]},"sidebar":"tutorialSidebar","previous":{"title":"Resources","permalink":"/docs/appendices/resources"},"next":{"title":"Why Humanoid Robots?","permalink":"/docs/intro/why-humanoid-robots"}},{"id":"intro/why-humanoid-robots","title":"Why Humanoid Robots?","description":"Human-centered world design advantage, Training data abundance from human environments, Current landscape: Tesla Bot, Figure AI, Unitree, Future of humanoid robotics.","source":"@site/docs/intro/why-humanoid-robots.mdx","sourceDirName":"intro","slug":"/intro/why-humanoid-robots","permalink":"/docs/intro/why-humanoid-robots","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/intro/why-humanoid-robots.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"why-humanoid-robots","title":"Why Humanoid Robots?","sidebar_label":"Why Humanoid Robots?","sidebar_position":2,"description":"Human-centered world design advantage, Training data abundance from human environments, Current landscape: Tesla Bot, Figure AI, Unitree, Future of humanoid robotics.","keywords":["humanoid-robots","tesla-bot","figure-ai","unitree","robotics-future"]},"sidebar":"tutorialSidebar","previous":{"title":"What is Physical AI?","permalink":"/docs/intro/what-is-physical-ai"},"next":{"title":"Course Overview","permalink":"/docs/intro/course-overview"}},{"id":"module-1-ros2/architecture","title":"ROS 2 Architecture & Core Concepts","description":"ROS 1 vs ROS 2 differences, DDS explained, Workspace structure, Packages, nodes, executables, colcon build system.","source":"@site/docs/module-1-ros2/architecture.mdx","sourceDirName":"module-1-ros2","slug":"/module-1-ros2/architecture","permalink":"/docs/module-1-ros2/architecture","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-1-ros2/architecture.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"architecture","title":"ROS 2 Architecture & Core Concepts","sidebar_label":"ROS 2 Architecture","sidebar_position":1,"description":"ROS 1 vs ROS 2 differences, DDS explained, Workspace structure, Packages, nodes, executables, colcon build system.","keywords":["ros2","architecture","dds","workspace","packages","nodes","colcon"]},"sidebar":"tutorialSidebar","previous":{"title":"Part 1: The Robotic Nervous System - ROS 2","permalink":"/docs/category/part-1-the-robotic-nervous-system---ros-2"},"next":{"title":"Nodes, Topics, Services","permalink":"/docs/module-1-ros2/nodes-topics-services"}},{"id":"module-1-ros2/bridging-agents","title":"Bridging Python Agents to ROS Controllers","description":"AI Agent architecture, Connecting LLM outputs to ROS 2 actions, Action clients in Python, Message serialization, Real-time considerations, Error handling.","source":"@site/docs/module-1-ros2/bridging-agents.mdx","sourceDirName":"module-1-ros2","slug":"/module-1-ros2/bridging-agents","permalink":"/docs/module-1-ros2/bridging-agents","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-1-ros2/bridging-agents.mdx","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"id":"bridging-agents","title":"Bridging Python Agents to ROS Controllers","sidebar_label":"Bridging Agents","sidebar_position":6,"description":"AI Agent architecture, Connecting LLM outputs to ROS 2 actions, Action clients in Python, Message serialization, Real-time considerations, Error handling.","keywords":["ros2","python","agent","llm","action-client","message-serialization"]},"sidebar":"tutorialSidebar","previous":{"title":"Launch Files & Parameters","permalink":"/docs/module-1-ros2/launch-files"},"next":{"title":"Part 2: The Digital Twin - Gazebo & Unity","permalink":"/docs/category/part-2-the-digital-twin---gazebo--unity"}},{"id":"module-1-ros2/launch-files","title":"Launch Files and Parameter Management","description":"Python launch file syntax, Launching multiple nodes, Parameters (declaration and usage), YAML parameter files, Remapping topics, Conditional launching.","source":"@site/docs/module-1-ros2/launch-files.mdx","sourceDirName":"module-1-ros2","slug":"/module-1-ros2/launch-files","permalink":"/docs/module-1-ros2/launch-files","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-1-ros2/launch-files.mdx","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"id":"launch-files","title":"Launch Files and Parameter Management","sidebar_label":"Launch Files & Parameters","sidebar_position":5,"description":"Python launch file syntax, Launching multiple nodes, Parameters (declaration and usage), YAML parameter files, Remapping topics, Conditional launching.","keywords":["ros2","launch-files","python","parameters","yaml","remapping"]},"sidebar":"tutorialSidebar","previous":{"title":"URDF for Humanoids","permalink":"/docs/module-1-ros2/urdf-humanoids"},"next":{"title":"Bridging Agents","permalink":"/docs/module-1-ros2/bridging-agents"}},{"id":"module-1-ros2/nodes-topics-services","title":"Nodes, Topics, and Services","description":"Nodes as building blocks, Pub/Sub pattern with Topics, Messages (std_msgs, geometry_msgs), Request/Response with Services, Actions for long-running tasks, QoS settings.","source":"@site/docs/module-1-ros2/nodes-topics-services.mdx","sourceDirName":"module-1-ros2","slug":"/module-1-ros2/nodes-topics-services","permalink":"/docs/module-1-ros2/nodes-topics-services","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-1-ros2/nodes-topics-services.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"nodes-topics-services","title":"Nodes, Topics, and Services","sidebar_label":"Nodes, Topics, Services","sidebar_position":2,"description":"Nodes as building blocks, Pub/Sub pattern with Topics, Messages (std_msgs, geometry_msgs), Request/Response with Services, Actions for long-running tasks, QoS settings.","keywords":["ros2","nodes","topics","services","actions","qos","pubsub"]},"sidebar":"tutorialSidebar","previous":{"title":"ROS 2 Architecture","permalink":"/docs/module-1-ros2/architecture"},"next":{"title":"Python Packages","permalink":"/docs/module-1-ros2/python-packages"}},{"id":"module-1-ros2/python-packages","title":"Building ROS 2 Packages with Python (rclpy)","description":"Python package structure, setup.py and package.xml, Entry points and console scripts, Dependencies management, Building and running.","source":"@site/docs/module-1-ros2/python-packages.mdx","sourceDirName":"module-1-ros2","slug":"/module-1-ros2/python-packages","permalink":"/docs/module-1-ros2/python-packages","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-1-ros2/python-packages.mdx","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"python-packages","title":"Building ROS 2 Packages with Python (rclpy)","sidebar_label":"Python Packages","sidebar_position":3,"description":"Python package structure, setup.py and package.xml, Entry points and console scripts, Dependencies management, Building and running.","keywords":["ros2","python","rclpy","package","setup.py","package.xml","colcon"]},"sidebar":"tutorialSidebar","previous":{"title":"Nodes, Topics, Services","permalink":"/docs/module-1-ros2/nodes-topics-services"},"next":{"title":"URDF for Humanoids","permalink":"/docs/module-1-ros2/urdf-humanoids"}},{"id":"module-1-ros2/urdf-humanoids","title":"Understanding URDF for Humanoids","description":"URDF (Unified Robot Description Format), XML structure, Visual, collision, inertial properties, Joint types, Building simple humanoid URDF, Visualizing in RViz2.","source":"@site/docs/module-1-ros2/urdf-humanoids.mdx","sourceDirName":"module-1-ros2","slug":"/module-1-ros2/urdf-humanoids","permalink":"/docs/module-1-ros2/urdf-humanoids","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-1-ros2/urdf-humanoids.mdx","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"urdf-humanoids","title":"Understanding URDF for Humanoids","sidebar_label":"URDF for Humanoids","sidebar_position":4,"description":"URDF (Unified Robot Description Format), XML structure, Visual, collision, inertial properties, Joint types, Building simple humanoid URDF, Visualizing in RViz2.","keywords":["urdf","xml","links","joints","humanoid","rviz2"]},"sidebar":"tutorialSidebar","previous":{"title":"Python Packages","permalink":"/docs/module-1-ros2/python-packages"},"next":{"title":"Launch Files & Parameters","permalink":"/docs/module-1-ros2/launch-files"}},{"id":"module-2-simulation/gazebo-setup","title":"Gazebo Simulation Environment Setup","description":"Gazebo Harmonic overview, Installation verification, GUI walkthrough, World files (.sdf), Loading robots, ros_gz_bridge setup.","source":"@site/docs/module-2-simulation/gazebo-setup.mdx","sourceDirName":"module-2-simulation","slug":"/module-2-simulation/gazebo-setup","permalink":"/docs/module-2-simulation/gazebo-setup","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-2-simulation/gazebo-setup.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"gazebo-setup","title":"Gazebo Simulation Environment Setup","sidebar_label":"Gazebo Setup","sidebar_position":1,"description":"Gazebo Harmonic overview, Installation verification, GUI walkthrough, World files (.sdf), Loading robots, ros_gz_bridge setup.","keywords":["gazebo","simulation","ros2","sdf","ros_gz_bridge"]},"sidebar":"tutorialSidebar","previous":{"title":"Part 2: The Digital Twin - Gazebo & Unity","permalink":"/docs/category/part-2-the-digital-twin---gazebo--unity"},"next":{"title":"URDF & SDF","permalink":"/docs/module-2-simulation/urdf-sdf"}},{"id":"module-2-simulation/hri-simulation","title":"Human-Robot Interaction in Simulation","description":"Simulating human actors, Gesture recognition setup, Proximity sensors, Social navigation, Testing HRI scenarios.","source":"@site/docs/module-2-simulation/hri-simulation.mdx","sourceDirName":"module-2-simulation","slug":"/module-2-simulation/hri-simulation","permalink":"/docs/module-2-simulation/hri-simulation","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-2-simulation/hri-simulation.mdx","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"id":"hri-simulation","title":"Human-Robot Interaction in Simulation","sidebar_label":"HRI in Simulation","sidebar_position":6,"description":"Simulating human actors, Gesture recognition setup, Proximity sensors, Social navigation, Testing HRI scenarios.","keywords":["hri","simulation","human-robot-interaction","gazebo","media-pipe"]},"sidebar":"tutorialSidebar","previous":{"title":"Sensor Simulation","permalink":"/docs/module-2-simulation/sensor-simulation"},"next":{"title":"High-Fidelity Rendering in Unity","permalink":"/docs/module-2-simulation/unity-rendering"}},{"id":"module-2-simulation/physics-simulation","title":"Simulating Physics, Gravity, and Collisions","description":"Physics engines (DART, Bullet, ODE), Gravity configuration, Collision detection, Friction and contact parameters, Inertia calculations, Physics step size.","source":"@site/docs/module-2-simulation/physics-simulation.mdx","sourceDirName":"module-2-simulation","slug":"/module-2-simulation/physics-simulation","permalink":"/docs/module-2-simulation/physics-simulation","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-2-simulation/physics-simulation.mdx","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"physics-simulation","title":"Simulating Physics, Gravity, and Collisions","sidebar_label":"Physics Simulation","sidebar_position":3,"description":"Physics engines (DART, Bullet, ODE), Gravity configuration, Collision detection, Friction and contact parameters, Inertia calculations, Physics step size.","keywords":["gazebo","physics","simulation","gravity","collisions","friction"]},"sidebar":"tutorialSidebar","previous":{"title":"URDF & SDF","permalink":"/docs/module-2-simulation/urdf-sdf"},"next":{"title":"Sensor Simulation","permalink":"/docs/module-2-simulation/sensor-simulation"}},{"id":"module-2-simulation/sensor-simulation","title":"Sensor Simulation (LiDAR, Depth Cameras, IMUs)","description":"Sensor plugins in Gazebo, LiDAR setup and configuration, Depth camera (RealSense) simulation, IMU implementation, Publishing to ROS 2 topics, Noise models.","source":"@site/docs/module-2-simulation/sensor-simulation.mdx","sourceDirName":"module-2-simulation","slug":"/module-2-simulation/sensor-simulation","permalink":"/docs/module-2-simulation/sensor-simulation","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-2-simulation/sensor-simulation.mdx","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"sensor-simulation","title":"Sensor Simulation (LiDAR, Depth Cameras, IMUs)","sidebar_label":"Sensor Simulation","sidebar_position":4,"description":"Sensor plugins in Gazebo, LiDAR setup and configuration, Depth camera (RealSense) simulation, IMU implementation, Publishing to ROS 2 topics, Noise models.","keywords":["gazebo","sensors","lidar","depth-camera","imu","ros2","noise-models"]},"sidebar":"tutorialSidebar","previous":{"title":"Physics Simulation","permalink":"/docs/module-2-simulation/physics-simulation"},"next":{"title":"HRI in Simulation","permalink":"/docs/module-2-simulation/hri-simulation"}},{"id":"module-2-simulation/unity-rendering","title":"High-Fidelity Rendering in Unity","description":"While Gazebo is an excellent general-purpose simulator, Unity offers superior visual fidelity and advanced rendering capabilities, making it ideal for simulating environments where appearance matters, such as for human-robot interaction or computer vision tasks that benefit from photorealistic scenes. Unity's rich game development ecosystem can be leveraged for advanced robotic simulations.","source":"@site/docs/module-2-simulation/unity-rendering.mdx","sourceDirName":"module-2-simulation","slug":"/module-2-simulation/unity-rendering","permalink":"/docs/module-2-simulation/unity-rendering","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-2-simulation/unity-rendering.mdx","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"HRI in Simulation","permalink":"/docs/module-2-simulation/hri-simulation"},"next":{"title":"Part 3: The AI-Robot Brain - NVIDIA Isaac","permalink":"/docs/category/part-3-the-ai-robot-brain---nvidia-isaac"}},{"id":"module-2-simulation/urdf-sdf","title":"URDF and SDF Robot Description Formats","description":"URDF vs SDF comparison, Converting URDF to SDF, SDF advanced features, Gazebo-specific URDF tags, Xacro macros.","source":"@site/docs/module-2-simulation/urdf-sdf.mdx","sourceDirName":"module-2-simulation","slug":"/module-2-simulation/urdf-sdf","permalink":"/docs/module-2-simulation/urdf-sdf","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-2-simulation/urdf-sdf.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"urdf-sdf","title":"URDF and SDF Robot Description Formats","sidebar_label":"URDF & SDF","sidebar_position":2,"description":"URDF vs SDF comparison, Converting URDF to SDF, SDF advanced features, Gazebo-specific URDF tags, Xacro macros.","keywords":["urdf","sdf","xacro","robot-description","gazebo"]},"sidebar":"tutorialSidebar","previous":{"title":"Gazebo Setup","permalink":"/docs/module-2-simulation/gazebo-setup"},"next":{"title":"Physics Simulation","permalink":"/docs/module-2-simulation/physics-simulation"}},{"id":"module-3-isaac/isaac-overview","title":"NVIDIA Isaac SDK and Isaac Sim Overview","description":"Isaac ecosystem components, Isaac Sim (Omniverse-based), Isaac ROS vs Isaac SDK, Hardware requirements, Installation and licensing, First scene creation.","source":"@site/docs/module-3-isaac/isaac-overview.mdx","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/isaac-overview","permalink":"/docs/module-3-isaac/isaac-overview","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-3-isaac/isaac-overview.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"isaac-overview","title":"NVIDIA Isaac SDK and Isaac Sim Overview","sidebar_label":"Isaac Overview","sidebar_position":1,"description":"Isaac ecosystem components, Isaac Sim (Omniverse-based), Isaac ROS vs Isaac SDK, Hardware requirements, Installation and licensing, First scene creation.","keywords":["nvidia-isaac","isaac-sim","omniverse","isaac-ros","robotics-simulation"]},"sidebar":"tutorialSidebar","previous":{"title":"Part 3: The AI-Robot Brain - NVIDIA Isaac","permalink":"/docs/category/part-3-the-ai-robot-brain---nvidia-isaac"},"next":{"title":"Synthetic Data","permalink":"/docs/module-3-isaac/synthetic-data"}},{"id":"module-3-isaac/nav2","title":"Nav2: Path Planning for Bipedal Movement","description":"Nav2 stack overview, Costmaps for navigation, Path planners (NavFn, Smac), Behavior trees, Adapting for bipedal robots, Dynamic obstacle avoidance.","source":"@site/docs/module-3-isaac/nav2.mdx","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/nav2","permalink":"/docs/module-3-isaac/nav2","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-3-isaac/nav2.mdx","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"nav2","title":"Nav2: Path Planning for Bipedal Movement","sidebar_label":"Nav2","sidebar_position":4,"description":"Nav2 stack overview, Costmaps for navigation, Path planners (NavFn, Smac), Behavior trees, Adapting for bipedal robots, Dynamic obstacle avoidance.","keywords":["nav2","ros2","navigation","bipedal","path-planning","behavior-trees"]},"sidebar":"tutorialSidebar","previous":{"title":"Isaac ROS VSLAM","permalink":"/docs/module-3-isaac/vslam"},"next":{"title":"RL for Robot Control","permalink":"/docs/module-3-isaac/reinforcement-learning"}},{"id":"module-3-isaac/reinforcement-learning","title":"Reinforcement Learning for Robot Control","description":"RL basics for robotics, Isaac Gym / Isaac Lab, Training locomotion policies, Reward function design, Policy networks (Actor-Critic), Training pipeline.","source":"@site/docs/module-3-isaac/reinforcement-learning.mdx","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/reinforcement-learning","permalink":"/docs/module-3-isaac/reinforcement-learning","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-3-isaac/reinforcement-learning.mdx","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"id":"reinforcement-learning","title":"Reinforcement Learning for Robot Control","sidebar_label":"RL for Robot Control","sidebar_position":5,"description":"RL basics for robotics, Isaac Gym / Isaac Lab, Training locomotion policies, Reward function design, Policy networks (Actor-Critic), Training pipeline.","keywords":["reinforcement-learning","rl","robotics","isaac-gym","isaac-lab","policy-networks","reward-function"]},"sidebar":"tutorialSidebar","previous":{"title":"Nav2","permalink":"/docs/module-3-isaac/nav2"},"next":{"title":"Sim-to-Real Transfer","permalink":"/docs/module-3-isaac/sim-to-real"}},{"id":"module-3-isaac/sim-to-real","title":"Sim-to-Real Transfer Techniques","description":"Reality gap problem, Domain randomization strategies, System identification, Progressive training, Deploying to Jetson, Testing and validation.","source":"@site/docs/module-3-isaac/sim-to-real.mdx","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/sim-to-real","permalink":"/docs/module-3-isaac/sim-to-real","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-3-isaac/sim-to-real.mdx","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"id":"sim-to-real","title":"Sim-to-Real Transfer Techniques","sidebar_label":"Sim-to-Real Transfer","sidebar_position":6,"description":"Reality gap problem, Domain randomization strategies, System identification, Progressive training, Deploying to Jetson, Testing and validation.","keywords":["sim-to-real","reality-gap","domain-randomization","system-identification","jetson","robotics"]},"sidebar":"tutorialSidebar","previous":{"title":"RL for Robot Control","permalink":"/docs/module-3-isaac/reinforcement-learning"},"next":{"title":"Part 4: Vision-Language-Action - VLA","permalink":"/docs/category/part-4-vision-language-action---vla"}},{"id":"module-3-isaac/synthetic-data","title":"Photorealistic Simulation & Synthetic Data Generation","description":"Why synthetic data, Domain randomization, Replicator for data generation, Generating labeled datasets, Training-ready pipelines, Quality validation.","source":"@site/docs/module-3-isaac/synthetic-data.mdx","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/synthetic-data","permalink":"/docs/module-3-isaac/synthetic-data","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-3-isaac/synthetic-data.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"synthetic-data","title":"Photorealistic Simulation & Synthetic Data Generation","sidebar_label":"Synthetic Data","sidebar_position":2,"description":"Why synthetic data, Domain randomization, Replicator for data generation, Generating labeled datasets, Training-ready pipelines, Quality validation.","keywords":["synthetic-data","domain-randomization","isaac-replicator","computer-vision","deep-learning"]},"sidebar":"tutorialSidebar","previous":{"title":"Isaac Overview","permalink":"/docs/module-3-isaac/isaac-overview"},"next":{"title":"Isaac ROS VSLAM","permalink":"/docs/module-3-isaac/vslam"}},{"id":"module-3-isaac/vslam","title":"Isaac ROS: Hardware-Accelerated VSLAM","description":"VSLAM (Visual SLAM) explained, Isaac ROS packages, cuVSLAM (GPU-accelerated), Stereo camera input, Real-time localization, Performance benchmarks.","source":"@site/docs/module-3-isaac/vslam.mdx","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/vslam","permalink":"/docs/module-3-isaac/vslam","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-3-isaac/vslam.mdx","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"vslam","title":"Isaac ROS: Hardware-Accelerated VSLAM","sidebar_label":"Isaac ROS VSLAM","sidebar_position":3,"description":"VSLAM (Visual SLAM) explained, Isaac ROS packages, cuVSLAM (GPU-accelerated), Stereo camera input, Real-time localization, Performance benchmarks.","keywords":["isaac-ros","vslam","slam","nvidia-gpu","real-time","localization"]},"sidebar":"tutorialSidebar","previous":{"title":"Synthetic Data","permalink":"/docs/module-3-isaac/synthetic-data"},"next":{"title":"Nav2","permalink":"/docs/module-3-isaac/nav2"}},{"id":"module-4-vla/cognitive-planning","title":"Cognitive Planning with LLMs","description":"Large Language Models (LLMs) are demonstrating remarkable abilities in understanding, reasoning, and generating human-like text. This cognitive prowess can be harnessed to enable robots to perform high-level planning, interpret complex commands, and even adapt to novel situations, effectively giving robots a \"cognitive brain.\" This chapter explores how LLMs can be used for cognitive planning in robotics.","source":"@site/docs/module-4-vla/cognitive-planning.mdx","sourceDirName":"module-4-vla","slug":"/module-4-vla/cognitive-planning","permalink":"/docs/module-4-vla/cognitive-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-4-vla/cognitive-planning.mdx","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Conversational AI","permalink":"/docs/module-4-vla/conversational-ai"},"next":{"title":"Part 5: Capstone Project","permalink":"/docs/category/part-5-capstone-project"}},{"id":"module-4-vla/conversational-ai","title":"Integrating GPT Models for Conversational Robotics","description":"Conversational AI for robots, GPT-4 API integration, Conversation state management, Contextual memory, Natural responses, Safety filters.","source":"@site/docs/module-4-vla/conversational-ai.mdx","sourceDirName":"module-4-vla","slug":"/module-4-vla/conversational-ai","permalink":"/docs/module-4-vla/conversational-ai","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-4-vla/conversational-ai.mdx","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"id":"conversational-ai","title":"Integrating GPT Models for Conversational Robotics","sidebar_label":"Conversational AI","sidebar_position":7,"description":"Conversational AI for robots, GPT-4 API integration, Conversation state management, Contextual memory, Natural responses, Safety filters.","keywords":["gpt","llms","conversational-ai","robotics","openai"]},"sidebar":"tutorialSidebar","previous":{"title":"Multi-modal Interaction","permalink":"/docs/module-4-vla/multimodal"},"next":{"title":"Cognitive Planning with LLMs","permalink":"/docs/module-4-vla/cognitive-planning"}},{"id":"module-4-vla/kinematics","title":"Humanoid Robot Kinematics and Dynamics","description":"Forward kinematics, Inverse kinematics (IK), Denavit-Hartenberg parameters, Dynamics (Forces and torques), PyBullet simulation, IK solvers (KDL, TRAC-IK).","source":"@site/docs/module-4-vla/kinematics.mdx","sourceDirName":"module-4-vla","slug":"/module-4-vla/kinematics","permalink":"/docs/module-4-vla/kinematics","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-4-vla/kinematics.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"kinematics","title":"Humanoid Robot Kinematics and Dynamics","sidebar_label":"Kinematics & Dynamics","sidebar_position":1,"description":"Forward kinematics, Inverse kinematics (IK), Denavit-Hartenberg parameters, Dynamics (Forces and torques), PyBullet simulation, IK solvers (KDL, TRAC-IK).","keywords":["robotics","kinematics","dynamics","humanoid","pybullet","ik"]},"sidebar":"tutorialSidebar","previous":{"title":"Part 4: Vision-Language-Action - VLA","permalink":"/docs/category/part-4-vision-language-action---vla"},"next":{"title":"Bipedal Locomotion","permalink":"/docs/module-4-vla/locomotion"}},{"id":"module-4-vla/locomotion","title":"Bipedal Locomotion and Balance Control","description":"Zero Moment Point (ZMP), Center of Mass (CoM) control, Gait generation, Walking pattern generators, Balance recovery, Terrain adaptation.","source":"@site/docs/module-4-vla/locomotion.mdx","sourceDirName":"module-4-vla","slug":"/module-4-vla/locomotion","permalink":"/docs/module-4-vla/locomotion","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-4-vla/locomotion.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"locomotion","title":"Bipedal Locomotion and Balance Control","sidebar_label":"Bipedal Locomotion","sidebar_position":2,"description":"Zero Moment Point (ZMP), Center of Mass (CoM) control, Gait generation, Walking pattern generators, Balance recovery, Terrain adaptation.","keywords":["bipedal","locomotion","zmp","com","balance-control","gait"]},"sidebar":"tutorialSidebar","previous":{"title":"Kinematics & Dynamics","permalink":"/docs/module-4-vla/kinematics"},"next":{"title":"Manipulation & Grasping","permalink":"/docs/module-4-vla/manipulation"}},{"id":"module-4-vla/manipulation","title":"Manipulation and Grasping with Humanoid Hands","description":"Humanoid hand design, Grasp types and taxonomy, Grasp planning algorithms, Force control, Object manipulation, Tool use.","source":"@site/docs/module-4-vla/manipulation.mdx","sourceDirName":"module-4-vla","slug":"/module-4-vla/manipulation","permalink":"/docs/module-4-vla/manipulation","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-4-vla/manipulation.mdx","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"manipulation","title":"Manipulation and Grasping with Humanoid Hands","sidebar_label":"Manipulation & Grasping","sidebar_position":3,"description":"Humanoid hand design, Grasp types and taxonomy, Grasp planning algorithms, Force control, Object manipulation, Tool use.","keywords":["manipulation","grasping","humanoid-hands","force-control","robotics"]},"sidebar":"tutorialSidebar","previous":{"title":"Bipedal Locomotion","permalink":"/docs/module-4-vla/locomotion"},"next":{"title":"Voice-to-Action","permalink":"/docs/module-4-vla/voice-to-action"}},{"id":"module-4-vla/multimodal","title":"Multi-modal Interaction (Speech, Gesture, Vision)","description":"Multi-modal fusion strategies, Gesture recognition with MediaPipe, Combining voice + gesture, Visual attention, Context-aware responses.","source":"@site/docs/module-4-vla/multimodal.mdx","sourceDirName":"module-4-vla","slug":"/module-4-vla/multimodal","permalink":"/docs/module-4-vla/multimodal","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-4-vla/multimodal.mdx","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"id":"multimodal","title":"Multi-modal Interaction (Speech, Gesture, Vision)","sidebar_label":"Multi-modal Interaction","sidebar_position":6,"description":"Multi-modal fusion strategies, Gesture recognition with MediaPipe, Combining voice + gesture, Visual attention, Context-aware responses.","keywords":["multi-modal","gesture-recognition","mediapipe","visual-attention","hri"]},"sidebar":"tutorialSidebar","previous":{"title":"Voice-to-Action","permalink":"/docs/module-4-vla/voice-to-action"},"next":{"title":"Conversational AI","permalink":"/docs/module-4-vla/conversational-ai"}},{"id":"module-4-vla/voice-to-action","title":"Voice-to-Action with OpenAI Whisper","description":"Speech recognition overview, Whisper model variants, Local Whisper deployment, Real-time audio streaming, Command parsing, Error handling.","source":"@site/docs/module-4-vla/voice-to-action.mdx","sourceDirName":"module-4-vla","slug":"/module-4-vla/voice-to-action","permalink":"/docs/module-4-vla/voice-to-action","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-4-vla/voice-to-action.mdx","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"voice-to-action","title":"Voice-to-Action with OpenAI Whisper","sidebar_label":"Voice-to-Action","sidebar_position":4,"description":"Speech recognition overview, Whisper model variants, Local Whisper deployment, Real-time audio streaming, Command parsing, Error handling.","keywords":["voice-to-action","openai-whisper","speech-recognition","ros2","command-parsing"]},"sidebar":"tutorialSidebar","previous":{"title":"Manipulation & Grasping","permalink":"/docs/module-4-vla/manipulation"},"next":{"title":"Multi-modal Interaction","permalink":"/docs/module-4-vla/multimodal"}}],"drafts":[],"sidebars":{"tutorialSidebar":[{"type":"category","label":"Part 1: The Robotic Nervous System - ROS 2","collapsible":true,"collapsed":true,"items":[{"type":"doc","id":"module-1-ros2/architecture","label":"ROS 2 Architecture"},{"type":"doc","id":"module-1-ros2/nodes-topics-services","label":"Nodes, Topics, Services"},{"type":"doc","id":"module-1-ros2/python-packages","label":"Python Packages"},{"type":"doc","id":"module-1-ros2/urdf-humanoids","label":"URDF for Humanoids"},{"type":"doc","id":"module-1-ros2/launch-files","label":"Launch Files & Parameters"},{"type":"doc","id":"module-1-ros2/bridging-agents","label":"Bridging Agents"}],"link":{"type":"generated-index","description":"Middleware for robot control","slug":"/category/part-1-the-robotic-nervous-system---ros-2","permalink":"/docs/category/part-1-the-robotic-nervous-system---ros-2"}},{"type":"category","label":"Part 2: The Digital Twin - Gazebo & Unity","collapsible":true,"collapsed":true,"items":[{"type":"doc","id":"module-2-simulation/gazebo-setup","label":"Gazebo Setup"},{"type":"doc","id":"module-2-simulation/urdf-sdf","label":"URDF & SDF"},{"type":"doc","id":"module-2-simulation/physics-simulation","label":"Physics Simulation"},{"type":"doc","id":"module-2-simulation/sensor-simulation","label":"Sensor Simulation"},{"type":"doc","id":"module-2-simulation/hri-simulation","label":"HRI in Simulation"},{"type":"doc","id":"module-2-simulation/unity-rendering"}],"link":{"type":"generated-index","description":"Physics simulation and environment building","slug":"/category/part-2-the-digital-twin---gazebo--unity","permalink":"/docs/category/part-2-the-digital-twin---gazebo--unity"}},{"type":"category","label":"Part 3: The AI-Robot Brain - NVIDIA Isaac","collapsible":true,"collapsed":true,"items":[{"type":"doc","id":"module-3-isaac/isaac-overview","label":"Isaac Overview"},{"type":"doc","id":"module-3-isaac/synthetic-data","label":"Synthetic Data"},{"type":"doc","id":"module-3-isaac/vslam","label":"Isaac ROS VSLAM"},{"type":"doc","id":"module-3-isaac/nav2","label":"Nav2"},{"type":"doc","id":"module-3-isaac/reinforcement-learning","label":"RL for Robot Control"},{"type":"doc","id":"module-3-isaac/sim-to-real","label":"Sim-to-Real Transfer"}],"link":{"type":"generated-index","description":"Advanced perception and training","slug":"/category/part-3-the-ai-robot-brain---nvidia-isaac","permalink":"/docs/category/part-3-the-ai-robot-brain---nvidia-isaac"}},{"type":"category","label":"Part 4: Vision-Language-Action - VLA","collapsible":true,"collapsed":true,"items":[{"type":"doc","id":"module-4-vla/kinematics","label":"Kinematics & Dynamics"},{"type":"doc","id":"module-4-vla/locomotion","label":"Bipedal Locomotion"},{"type":"doc","id":"module-4-vla/manipulation","label":"Manipulation & Grasping"},{"type":"doc","id":"module-4-vla/voice-to-action","label":"Voice-to-Action"},{"type":"doc","id":"module-4-vla/multimodal","label":"Multi-modal Interaction"},{"type":"doc","id":"module-4-vla/conversational-ai","label":"Conversational AI"},{"type":"doc","id":"module-4-vla/cognitive-planning"}],"link":{"type":"generated-index","description":"Convergence of LLMs and Robotics","slug":"/category/part-4-vision-language-action---vla","permalink":"/docs/category/part-4-vision-language-action---vla"}},{"type":"category","label":"Part 5: Capstone Project","collapsible":true,"collapsed":true,"items":[{"type":"doc","id":"capstone/capstone-overview","label":"Project Overview"},{"type":"doc","id":"capstone/capstone-architecture","label":"Architecture Design"},{"type":"doc","id":"capstone/voice-pipeline","label":"Voice Pipeline"},{"type":"doc","id":"capstone/capstone-navigation","label":"Navigation"},{"type":"doc","id":"capstone/capstone-manipulation","label":"Manipulation"},{"type":"doc","id":"capstone/capstone-integration","label":"Integration & Testing"},{"type":"doc","id":"capstone/capstone-deployment","label":"Deployment & Demo"}],"link":{"type":"generated-index","description":"The Autonomous Humanoid","slug":"/category/part-5-capstone-project","permalink":"/docs/category/part-5-capstone-project"}},{"type":"category","label":"Appendices","collapsible":true,"collapsed":true,"items":[{"type":"doc","id":"appendices/hardware-setup","label":"Hardware Setup"},{"type":"doc","id":"appendices/cloud-setup","label":"Cloud Lab Setup"},{"type":"doc","id":"appendices/troubleshooting","label":"Troubleshooting"},{"type":"doc","id":"appendices/glossary","label":"Glossary"},{"type":"doc","id":"appendices/resources","label":"Resources"}],"link":{"type":"generated-index","description":"Supplemental materials","slug":"/category/appendices","permalink":"/docs/category/appendices"}},{"type":"category","label":"intro","collapsible":true,"collapsed":true,"items":[{"type":"doc","id":"intro/what-is-physical-ai","label":"What is Physical AI?"},{"type":"doc","id":"intro/why-humanoid-robots","label":"Why Humanoid Robots?"},{"type":"doc","id":"intro/course-overview","label":"Course Overview"},{"type":"doc","id":"intro/environment-setup","label":"Environment Setup"}]}]}}]}},"docusaurus-plugin-content-blog":{"default":{"blogSidebarTitle":"Recent posts","blogPosts":[],"blogListPaginated":[],"blogTags":{},"blogTagsListPath":"/blog/tags"}},"docusaurus-plugin-content-pages":{"default":null},"docusaurus-plugin-debug":{},"docusaurus-plugin-svgr":{},"docusaurus-theme-classic":{},"docusaurus-bootstrap-plugin":{},"docusaurus-mdx-fallback-plugin":{}}}