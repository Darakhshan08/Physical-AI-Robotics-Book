{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Introduction","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/introduction/what-is-physical-ai","label":"What is Physical AI?","docId":"introduction/what-is-physical-ai","unlisted":false},{"type":"link","href":"/docs/introduction/why-humanoid-robots","label":"Why Humanoid Robots?","docId":"introduction/why-humanoid-robots","unlisted":false},{"type":"link","href":"/docs/introduction/course-overview","label":"Course Overview","docId":"introduction/course-overview","unlisted":false},{"type":"link","href":"/docs/introduction/environment-setup","label":"Environment Setup","docId":"introduction/environment-setup","unlisted":false}]},{"type":"category","label":"Part 1: The Robotic Nervous System - ROS 2","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/module-1-ros2/architecture","label":"ROS 2 Architecture","docId":"module-1-ros2/architecture","unlisted":false},{"type":"link","href":"/docs/module-1-ros2/nodes-topics-services","label":"Nodes, Topics, Services","docId":"module-1-ros2/nodes-topics-services","unlisted":false},{"type":"link","href":"/docs/module-1-ros2/python-packages","label":"Python Packages","docId":"module-1-ros2/python-packages","unlisted":false},{"type":"link","href":"/docs/module-1-ros2/urdf-humanoids","label":"URDF for Humanoids","docId":"module-1-ros2/urdf-humanoids","unlisted":false},{"type":"link","href":"/docs/module-1-ros2/launch-files","label":"Launch Files & Parameters","docId":"module-1-ros2/launch-files","unlisted":false},{"type":"link","href":"/docs/module-1-ros2/bridging-agents","label":"Bridging Agents","docId":"module-1-ros2/bridging-agents","unlisted":false}],"href":"/docs/category/part-1-the-robotic-nervous-system---ros-2"},{"type":"category","label":"Part 2: The Digital Twin - Gazebo & Unity","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/module-2-simulation/gazebo-setup","label":"Gazebo Setup","docId":"module-2-simulation/gazebo-setup","unlisted":false},{"type":"link","href":"/docs/module-2-simulation/urdf-sdf","label":"URDF & SDF","docId":"module-2-simulation/urdf-sdf","unlisted":false},{"type":"link","href":"/docs/module-2-simulation/physics-simulation","label":"Physics Simulation","docId":"module-2-simulation/physics-simulation","unlisted":false},{"type":"link","href":"/docs/module-2-simulation/sensor-simulation","label":"Sensor Simulation","docId":"module-2-simulation/sensor-simulation","unlisted":false},{"type":"link","href":"/docs/module-2-simulation/hri-simulation","label":"HRI in Simulation","docId":"module-2-simulation/hri-simulation","unlisted":false},{"type":"link","href":"/docs/module-2-simulation/unity-rendering","label":"High-Fidelity Rendering in Unity","docId":"module-2-simulation/unity-rendering","unlisted":false}],"href":"/docs/category/part-2-the-digital-twin---gazebo--unity"},{"type":"category","label":"Part 3: The AI-Robot Brain - NVIDIA Isaac","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/module-3-isaac/isaac-overview","label":"Isaac Overview","docId":"module-3-isaac/isaac-overview","unlisted":false},{"type":"link","href":"/docs/module-3-isaac/synthetic-data","label":"Synthetic Data","docId":"module-3-isaac/synthetic-data","unlisted":false},{"type":"link","href":"/docs/module-3-isaac/vslam","label":"Isaac ROS VSLAM","docId":"module-3-isaac/vslam","unlisted":false},{"type":"link","href":"/docs/module-3-isaac/nav2","label":"Nav2","docId":"module-3-isaac/nav2","unlisted":false},{"type":"link","href":"/docs/module-3-isaac/reinforcement-learning","label":"RL for Robot Control","docId":"module-3-isaac/reinforcement-learning","unlisted":false},{"type":"link","href":"/docs/module-3-isaac/sim-to-real","label":"Sim-to-Real Transfer","docId":"module-3-isaac/sim-to-real","unlisted":false}],"href":"/docs/category/part-3-the-ai-robot-brain---nvidia-isaac"},{"type":"category","label":"Part 4: Vision-Language-Action - VLA","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/module-4-vla/kinematics","label":"Kinematics & Dynamics","docId":"module-4-vla/kinematics","unlisted":false},{"type":"link","href":"/docs/module-4-vla/locomotion","label":"Bipedal Locomotion","docId":"module-4-vla/locomotion","unlisted":false},{"type":"link","href":"/docs/module-4-vla/manipulation","label":"Manipulation & Grasping","docId":"module-4-vla/manipulation","unlisted":false},{"type":"link","href":"/docs/module-4-vla/voice-to-action","label":"Voice-to-Action","docId":"module-4-vla/voice-to-action","unlisted":false},{"type":"link","href":"/docs/module-4-vla/multimodal","label":"Multi-modal Interaction","docId":"module-4-vla/multimodal","unlisted":false},{"type":"link","href":"/docs/module-4-vla/conversational-ai","label":"Conversational AI","docId":"module-4-vla/conversational-ai","unlisted":false},{"type":"link","href":"/docs/module-4-vla/cognitive-planning","label":"Cognitive Planning with LLMs","docId":"module-4-vla/cognitive-planning","unlisted":false}],"href":"/docs/category/part-4-vision-language-action---vla"},{"type":"category","label":"Part 5: Capstone Project","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/capstone/capstone-overview","label":"Project Overview","docId":"capstone/capstone-overview","unlisted":false},{"type":"link","href":"/docs/capstone/capstone-architecture","label":"Architecture Design","docId":"capstone/capstone-architecture","unlisted":false},{"type":"link","href":"/docs/capstone/voice-pipeline","label":"Voice Pipeline","docId":"capstone/voice-pipeline","unlisted":false},{"type":"link","href":"/docs/capstone/capstone-navigation","label":"Navigation","docId":"capstone/capstone-navigation","unlisted":false},{"type":"link","href":"/docs/capstone/capstone-manipulation","label":"Manipulation","docId":"capstone/capstone-manipulation","unlisted":false},{"type":"link","href":"/docs/capstone/capstone-integration","label":"Integration & Testing","docId":"capstone/capstone-integration","unlisted":false},{"type":"link","href":"/docs/capstone/capstone-deployment","label":"Deployment & Demo","docId":"capstone/capstone-deployment","unlisted":false}],"href":"/docs/category/part-5-capstone-project"},{"type":"category","label":"Appendices","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/appendices/hardware-setup","label":"Hardware Setup","docId":"appendices/hardware-setup","unlisted":false},{"type":"link","href":"/docs/appendices/cloud-setup","label":"Cloud Lab Setup","docId":"appendices/cloud-setup","unlisted":false},{"type":"link","href":"/docs/appendices/troubleshooting","label":"Troubleshooting","docId":"appendices/troubleshooting","unlisted":false},{"type":"link","href":"/docs/appendices/glossary","label":"Glossary","docId":"appendices/glossary","unlisted":false},{"type":"link","href":"/docs/appendices/resources","label":"Resources","docId":"appendices/resources","unlisted":false}],"href":"/docs/category/appendices"}]},"docs":{"appendices/cloud-setup":{"id":"appendices/cloud-setup","title":"Cloud Lab Setup","description":"AWS RoboMaker setup, NVIDIA Omniverse Cloud, Cost optimization, Remote development workflow.","sidebar":"tutorialSidebar"},"appendices/glossary":{"id":"appendices/glossary","title":"Glossary of Terms","description":"100+ robotics and AI terms, Alphabetical listing.","sidebar":"tutorialSidebar"},"appendices/hardware-setup":{"id":"appendices/hardware-setup","title":"Hardware Setup Guides","description":"Jetson Orin Nano complete setup, Intel RealSense D435i configuration, ReSpeaker microphone setup, Unitree Go2/G1 SDK, Network configuration.","sidebar":"tutorialSidebar"},"appendices/resources":{"id":"appendices/resources","title":"Additional Resources","description":"Official documentation links, Recommended courses, Research papers, Community resources, GitHub repositories.","sidebar":"tutorialSidebar"},"appendices/troubleshooting":{"id":"appendices/troubleshooting","title":"Troubleshooting Common Issues","description":"ROS 2 errors and fixes, Gazebo crashes, Isaac Sim GPU issues, Network problems, Build failures.","sidebar":"tutorialSidebar"},"capstone/capstone-architecture":{"id":"capstone/capstone-architecture","title":"System Architecture Design","description":"Node graph design, Topic/service mapping, Launch organization, Configuration management, Logging and debugging, Testing strategy.","sidebar":"tutorialSidebar"},"capstone/capstone-deployment":{"id":"capstone/capstone-deployment","title":"Deployment and Demo","description":"Sim-to-real checklist, Jetson deployment, Real robot config, Demo preparation, Recording and documentation, Future improvements.","sidebar":"tutorialSidebar"},"capstone/capstone-integration":{"id":"capstone/capstone-integration","title":"Integration and Testing","description":"System integration steps, Unit testing nodes, Integration testing, Simulation checklist, Performance profiling, Bug tracking.","sidebar":"tutorialSidebar"},"capstone/capstone-manipulation":{"id":"capstone/capstone-manipulation","title":"Object Detection and Manipulation","description":"Object detection model, Target localization, Approach planning, Grasp execution, Manipulation feedback, Error recovery.","sidebar":"tutorialSidebar"},"capstone/capstone-navigation":{"id":"capstone/capstone-navigation","title":"Path Planning and Navigation","description":"Environment mapping, Goal pose from commands, Nav2 integration, Obstacle avoidance, Recovery behaviors, Navigation monitoring.","sidebar":"tutorialSidebar"},"capstone/capstone-overview":{"id":"capstone/capstone-overview","title":"Capstone Project Overview","description":"Capstone requirements, System architecture, Success criteria, Milestone breakdown, Assessment rubric.","sidebar":"tutorialSidebar"},"capstone/voice-pipeline":{"id":"capstone/voice-pipeline","title":"Voice Command Processing Pipeline","description":"Microphone input, Whisper integration, Command classification, Intent extraction, ROS 2 action triggering, User feedback.","sidebar":"tutorialSidebar"},"introduction/course-overview":{"id":"introduction/course-overview","title":"Course Overview & Hardware Requirements","description":"13-week course breakdown, Hardware Tier 1, 2, 3 requirements, Cloud alternative, pricing tables.","sidebar":"tutorialSidebar"},"introduction/environment-setup":{"id":"introduction/environment-setup","title":"Environment Setup","description":"Ubuntu 22.04 LTS installation, ROS 2 Humble installation, Gazebo Harmonic setup, NVIDIA Isaac Sim (Omniverse) installation, Python venv and dependencies, VS Code configuration, Verification commands.","sidebar":"tutorialSidebar"},"introduction/what-is-physical-ai":{"id":"introduction/what-is-physical-ai","title":"What is Physical AI?","description":"Digital AI vs Embodied AI differences, Physical AI definition and core concepts, Real-world applications, Why robots need to understand physics.","sidebar":"tutorialSidebar"},"introduction/why-humanoid-robots":{"id":"introduction/why-humanoid-robots","title":"Why Humanoid Robots?","description":"Human-centered world design advantage, Training data abundance from human environments, Current landscape: Tesla Bot, Figure AI, Unitree, Future of humanoid robotics.","sidebar":"tutorialSidebar"},"module-1-ros2/architecture":{"id":"module-1-ros2/architecture","title":"ROS 2 Architecture & Core Concepts","description":"ROS 1 vs ROS 2 differences, DDS explained, Workspace structure, Packages, nodes, executables, colcon build system.","sidebar":"tutorialSidebar"},"module-1-ros2/bridging-agents":{"id":"module-1-ros2/bridging-agents","title":"Bridging Python Agents to ROS Controllers","description":"AI Agent architecture, Connecting LLM outputs to ROS 2 actions, Action clients in Python, Message serialization, Real-time considerations, Error handling.","sidebar":"tutorialSidebar"},"module-1-ros2/launch-files":{"id":"module-1-ros2/launch-files","title":"Launch Files and Parameter Management","description":"Python launch file syntax, Launching multiple nodes, Parameters (declaration and usage), YAML parameter files, Remapping topics, Conditional launching.","sidebar":"tutorialSidebar"},"module-1-ros2/nodes-topics-services":{"id":"module-1-ros2/nodes-topics-services","title":"Nodes, Topics, and Services","description":"Nodes as building blocks, Pub/Sub pattern with Topics, Messages (std_msgs, geometry_msgs), Request/Response with Services, Actions for long-running tasks, QoS settings.","sidebar":"tutorialSidebar"},"module-1-ros2/python-packages":{"id":"module-1-ros2/python-packages","title":"Building ROS 2 Packages with Python (rclpy)","description":"Python package structure, setup.py and package.xml, Entry points and console scripts, Dependencies management, Building and running.","sidebar":"tutorialSidebar"},"module-1-ros2/urdf-humanoids":{"id":"module-1-ros2/urdf-humanoids","title":"Understanding URDF for Humanoids","description":"URDF (Unified Robot Description Format), XML structure, Visual, collision, inertial properties, Joint types, Building simple humanoid URDF, Visualizing in RViz2.","sidebar":"tutorialSidebar"},"module-2-simulation/gazebo-setup":{"id":"module-2-simulation/gazebo-setup","title":"Gazebo Simulation Environment Setup","description":"Gazebo Harmonic overview, Installation verification, GUI walkthrough, World files (.sdf), Loading robots, ros_gz_bridge setup.","sidebar":"tutorialSidebar"},"module-2-simulation/hri-simulation":{"id":"module-2-simulation/hri-simulation","title":"Human-Robot Interaction in Simulation","description":"Simulating human actors, Gesture recognition setup, Proximity sensors, Social navigation, Testing HRI scenarios.","sidebar":"tutorialSidebar"},"module-2-simulation/physics-simulation":{"id":"module-2-simulation/physics-simulation","title":"Simulating Physics, Gravity, and Collisions","description":"Physics engines (DART, Bullet, ODE), Gravity configuration, Collision detection, Friction and contact parameters, Inertia calculations, Physics step size.","sidebar":"tutorialSidebar"},"module-2-simulation/sensor-simulation":{"id":"module-2-simulation/sensor-simulation","title":"Sensor Simulation (LiDAR, Depth Cameras, IMUs)","description":"Sensor plugins in Gazebo, LiDAR setup and configuration, Depth camera (RealSense) simulation, IMU implementation, Publishing to ROS 2 topics, Noise models.","sidebar":"tutorialSidebar"},"module-2-simulation/unity-rendering":{"id":"module-2-simulation/unity-rendering","title":"High-Fidelity Rendering in Unity","description":"While Gazebo is an excellent general-purpose simulator, Unity offers superior visual fidelity and advanced rendering capabilities, making it ideal for simulating environments where appearance matters, such as for human-robot interaction or computer vision tasks that benefit from photorealistic scenes. Unity's rich game development ecosystem can be leveraged for advanced robotic simulations.","sidebar":"tutorialSidebar"},"module-2-simulation/urdf-sdf":{"id":"module-2-simulation/urdf-sdf","title":"URDF and SDF Robot Description Formats","description":"URDF vs SDF comparison, Converting URDF to SDF, SDF advanced features, Gazebo-specific URDF tags, Xacro macros.","sidebar":"tutorialSidebar"},"module-3-isaac/isaac-overview":{"id":"module-3-isaac/isaac-overview","title":"NVIDIA Isaac SDK and Isaac Sim Overview","description":"Isaac ecosystem components, Isaac Sim (Omniverse-based), Isaac ROS vs Isaac SDK, Hardware requirements, Installation and licensing, First scene creation.","sidebar":"tutorialSidebar"},"module-3-isaac/nav2":{"id":"module-3-isaac/nav2","title":"Nav2: Path Planning for Bipedal Movement","description":"Nav2 stack overview, Costmaps for navigation, Path planners (NavFn, Smac), Behavior trees, Adapting for bipedal robots, Dynamic obstacle avoidance.","sidebar":"tutorialSidebar"},"module-3-isaac/reinforcement-learning":{"id":"module-3-isaac/reinforcement-learning","title":"Reinforcement Learning for Robot Control","description":"RL basics for robotics, Isaac Gym / Isaac Lab, Training locomotion policies, Reward function design, Policy networks (Actor-Critic), Training pipeline.","sidebar":"tutorialSidebar"},"module-3-isaac/sim-to-real":{"id":"module-3-isaac/sim-to-real","title":"Sim-to-Real Transfer Techniques","description":"Reality gap problem, Domain randomization strategies, System identification, Progressive training, Deploying to Jetson, Testing and validation.","sidebar":"tutorialSidebar"},"module-3-isaac/synthetic-data":{"id":"module-3-isaac/synthetic-data","title":"Photorealistic Simulation & Synthetic Data Generation","description":"Why synthetic data, Domain randomization, Replicator for data generation, Generating labeled datasets, Training-ready pipelines, Quality validation.","sidebar":"tutorialSidebar"},"module-3-isaac/vslam":{"id":"module-3-isaac/vslam","title":"Isaac ROS: Hardware-Accelerated VSLAM","description":"VSLAM (Visual SLAM) explained, Isaac ROS packages, cuVSLAM (GPU-accelerated), Stereo camera input, Real-time localization, Performance benchmarks.","sidebar":"tutorialSidebar"},"module-4-vla/cognitive-planning":{"id":"module-4-vla/cognitive-planning","title":"Cognitive Planning with LLMs","description":"Large Language Models (LLMs) are demonstrating remarkable abilities in understanding, reasoning, and generating human-like text. This cognitive prowess can be harnessed to enable robots to perform high-level planning, interpret complex commands, and even adapt to novel situations, effectively giving robots a \"cognitive brain.\" This chapter explores how LLMs can be used for cognitive planning in robotics.","sidebar":"tutorialSidebar"},"module-4-vla/conversational-ai":{"id":"module-4-vla/conversational-ai","title":"Integrating GPT Models for Conversational Robotics","description":"Conversational AI for robots, GPT-4 API integration, Conversation state management, Contextual memory, Natural responses, Safety filters.","sidebar":"tutorialSidebar"},"module-4-vla/kinematics":{"id":"module-4-vla/kinematics","title":"Humanoid Robot Kinematics and Dynamics","description":"Forward kinematics, Inverse kinematics (IK), Denavit-Hartenberg parameters, Dynamics (Forces and torques), PyBullet simulation, IK solvers (KDL, TRAC-IK).","sidebar":"tutorialSidebar"},"module-4-vla/locomotion":{"id":"module-4-vla/locomotion","title":"Bipedal Locomotion and Balance Control","description":"Zero Moment Point (ZMP), Center of Mass (CoM) control, Gait generation, Walking pattern generators, Balance recovery, Terrain adaptation.","sidebar":"tutorialSidebar"},"module-4-vla/manipulation":{"id":"module-4-vla/manipulation","title":"Manipulation and Grasping with Humanoid Hands","description":"Humanoid hand design, Grasp types and taxonomy, Grasp planning algorithms, Force control, Object manipulation, Tool use.","sidebar":"tutorialSidebar"},"module-4-vla/multimodal":{"id":"module-4-vla/multimodal","title":"Multi-modal Interaction (Speech, Gesture, Vision)","description":"Multi-modal fusion strategies, Gesture recognition with MediaPipe, Combining voice + gesture, Visual attention, Context-aware responses.","sidebar":"tutorialSidebar"},"module-4-vla/voice-to-action":{"id":"module-4-vla/voice-to-action","title":"Voice-to-Action with OpenAI Whisper","description":"Speech recognition overview, Whisper model variants, Local Whisper deployment, Real-time audio streaming, Command parsing, Error handling.","sidebar":"tutorialSidebar"}}}}