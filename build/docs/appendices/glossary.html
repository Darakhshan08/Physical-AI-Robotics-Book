<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-appendices/glossary" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Glossary of Terms | Physical AI &amp; Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://Darakhshan08.github.io/Physical-AI-Humanoid-Robotics-Textbook/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://Darakhshan08.github.io/Physical-AI-Humanoid-Robotics-Textbook/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://Darakhshan08.github.io/Physical-AI-Humanoid-Robotics-Textbook/docs/appendices/glossary"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Glossary of Terms | Physical AI &amp; Humanoid Robotics"><meta data-rh="true" name="description" content="100+ robotics and AI terms, Alphabetical listing."><meta data-rh="true" property="og:description" content="100+ robotics and AI terms, Alphabetical listing."><meta data-rh="true" name="keywords" content="glossary,robotics-terms,ai-terms"><link data-rh="true" rel="icon" href="/Physical-AI-Humanoid-Robotics-Textbook/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://Darakhshan08.github.io/Physical-AI-Humanoid-Robotics-Textbook/docs/appendices/glossary"><link data-rh="true" rel="alternate" href="https://Darakhshan08.github.io/Physical-AI-Humanoid-Robotics-Textbook/docs/appendices/glossary" hreflang="en"><link data-rh="true" rel="alternate" href="https://Darakhshan08.github.io/Physical-AI-Humanoid-Robotics-Textbook/docs/appendices/glossary" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Appendices","item":"https://Darakhshan08.github.io/Physical-AI-Humanoid-Robotics-Textbook/docs/category/appendices"},{"@type":"ListItem","position":2,"name":"Glossary","item":"https://Darakhshan08.github.io/Physical-AI-Humanoid-Robotics-Textbook/docs/appendices/glossary"}]}</script><link rel="stylesheet" href="/Physical-AI-Humanoid-Robotics-Textbook/assets/css/styles.43713d77.css">
<script src="/Physical-AI-Humanoid-Robotics-Textbook/assets/js/runtime~main.ce3c27b6.js" defer="defer"></script>
<script src="/Physical-AI-Humanoid-Robotics-Textbook/assets/js/main.7556e6b1.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Physical-AI-Humanoid-Robotics-Textbook/"><div class="navbar__logo"><img src="/Physical-AI-Humanoid-Robotics-Textbook/img/logo.svg" alt="My Project Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/Physical-AI-Humanoid-Robotics-Textbook/img/logo.svg" alt="My Project Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI &amp; Humanoid Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/category/part-1-the-robotic-nervous-system---ros-2">Book</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/category/part-1-the-robotic-nervous-system---ros-2"><span title="Part 1: The Robotic Nervous System - ROS 2" class="categoryLinkLabel_W154">Part 1: The Robotic Nervous System - ROS 2</span></a><button aria-label="Expand sidebar category &#x27;Part 1: The Robotic Nervous System - ROS 2&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/category/part-2-the-digital-twin---gazebo--unity"><span title="Part 2: The Digital Twin - Gazebo &amp; Unity" class="categoryLinkLabel_W154">Part 2: The Digital Twin - Gazebo &amp; Unity</span></a><button aria-label="Expand sidebar category &#x27;Part 2: The Digital Twin - Gazebo &amp; Unity&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/category/part-3-the-ai-robot-brain---nvidia-isaac"><span title="Part 3: The AI-Robot Brain - NVIDIA Isaac" class="categoryLinkLabel_W154">Part 3: The AI-Robot Brain - NVIDIA Isaac</span></a><button aria-label="Expand sidebar category &#x27;Part 3: The AI-Robot Brain - NVIDIA Isaac&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/category/part-4-vision-language-action---vla"><span title="Part 4: Vision-Language-Action - VLA" class="categoryLinkLabel_W154">Part 4: Vision-Language-Action - VLA</span></a><button aria-label="Expand sidebar category &#x27;Part 4: Vision-Language-Action - VLA&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/category/part-5-capstone-project"><span title="Part 5: Capstone Project" class="categoryLinkLabel_W154">Part 5: Capstone Project</span></a><button aria-label="Expand sidebar category &#x27;Part 5: Capstone Project&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/category/appendices"><span title="Appendices" class="categoryLinkLabel_W154">Appendices</span></a><button aria-label="Collapse sidebar category &#x27;Appendices&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/appendices/hardware-setup"><span title="Hardware Setup" class="linkLabel_WmDU">Hardware Setup</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/appendices/cloud-setup"><span title="Cloud Lab Setup" class="linkLabel_WmDU">Cloud Lab Setup</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/appendices/troubleshooting"><span title="Troubleshooting" class="linkLabel_WmDU">Troubleshooting</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/appendices/glossary"><span title="Glossary" class="linkLabel_WmDU">Glossary</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/appendices/resources"><span title="Resources" class="linkLabel_WmDU">Resources</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/intro/what-is-physical-ai"><span title="intro" class="categoryLinkLabel_W154">intro</span></a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/category/appendices"><span>Appendices</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Glossary</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Glossary of Terms</h1></header>
<p>This glossary provides definitions for over 100 key terms related to Physical AI, robotics, and associated technologies. It serves as a quick reference to ensure a common understanding of terminology throughout the book. Terms are listed alphabetically.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="a">A<a href="#a" class="hash-link" aria-label="Direct link to A" title="Direct link to A" translate="no">​</a></h2>
<p><strong>Action</strong>: In Reinforcement Learning, an action is a move made by an agent in an environment. In ROS 2, actions are a type of communication for long-running, goal-oriented tasks.</p>
<p><strong>Action Primitive</strong>: A low-level, robot-executable operation that forms the building blocks of more complex robot behaviors (e.g., <code>move_gripper_to_position</code>, <code>turn_base_by_angle</code>).</p>
<p><strong>Actor-Critic</strong>: A class of Reinforcement Learning algorithms that combine two neural networks: an &quot;actor&quot; to determine the policy (actions) and a &quot;critic&quot; to evaluate the value of those actions.</p>
<p><strong>Actuator</strong>: A component of a machine that is responsible for moving and controlling a mechanism or system (e.g., motors, servos).</p>
<p><strong>ADR (Architectural Decision Record)</strong>: A document that captures a significant architectural decision made along with its context, options, and consequences.</p>
<p><strong>AI (Artificial Intelligence)</strong>: The simulation of human intelligence in machines that are programmed to think like humans and mimic their actions.</p>
<p><strong>ALSA (Advanced Linux Sound Architecture)</strong>: A software framework and part of the Linux kernel that provides an API for sound card device drivers.</p>
<p><strong>AMCL (Adaptive Monte Carlo Localization)</strong>: A probabilistic localization algorithm for a robot in a 2D environment, typically used with a pre-existing map.</p>
<p><strong>Ament</strong>: The build system used by ROS 2, which is an evolution of <code>catkin</code> from ROS 1.</p>
<p><strong>API (Application Programming Interface)</strong>: A set of defined rules that enable different software applications to communicate with each other.</p>
<p><strong>ASR (Automatic Speech Recognition)</strong>: The process of converting spoken language into text.</p>
<p><strong>Autonomous Robot</strong>: A robot that can perform tasks or navigate an environment without continuous human guidance.</p>
<p><strong>AWS CLI (Amazon Web Services Command Line Interface)</strong>: A unified tool to manage your AWS services from the command line.</p>
<p><strong>AWS RoboMaker</strong>: A cloud-based service that makes it easy for developers to develop, test, and deploy robotics applications at scale.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="b">B<a href="#b" class="hash-link" aria-label="Direct link to B" title="Direct link to B" translate="no">​</a></h2>
<p><strong>Bash</strong>: A Unix shell and command language, commonly used for scripting in Linux environments.</p>
<p><strong>Behavior Tree (BT)</strong>: A mathematical model of plan execution that describes how an autonomous agent can select and execute tasks in a modular and hierarchical way.</p>
<p><strong>Bipedal Locomotion</strong>: The act of moving on two legs, as seen in humans and humanoid robots.</p>
<p><strong>Bounding Box</strong>: A rectangular frame that encloses a detected object in an image, typically used in object detection.</p>
<p><strong>Bullet Physics</strong>: An open-source, real-time physics simulation engine used in games and virtual reality, supported by Gazebo.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="c">C<a href="#c" class="hash-link" aria-label="Direct link to C" title="Direct link to C" translate="no">​</a></h2>
<p><strong>CAD (Computer-Aided Design)</strong>: Software used to design and document products, often producing 3D models.</p>
<p><strong>Capstone Project</strong>: A culminating project in an academic or professional program that allows students/engineers to demonstrate mastery of learned skills.</p>
<p><strong>CoM (Center of Mass)</strong>: The unique point where the weighted relative position of the distributed mass sums to zero. Crucial for robot balance.</p>
<p><strong>colcon</strong>: The build system for ROS 2, replacing <code>catkin</code> from ROS 1.</p>
<p><strong>Collision Geometry</strong>: The simplified 3D shape used by a physics engine to detect collisions between objects. Often distinct from the visual geometry.</p>
<p><strong>Computer Vision</strong>: A field of artificial intelligence that enables computers to &quot;see&quot; and interpret images and videos.</p>
<p><strong>Conversational AI</strong>: AI systems designed to simulate human conversation through text or voice.</p>
<p><strong>Costmap</strong>: A 2D grid map used by navigation systems to represent obstacles and areas a robot should avoid.</p>
<p><strong>CUDA (Compute Unified Device Architecture)</strong>: NVIDIA&#x27;s parallel computing platform and programming model for GPUs.</p>
<p><strong>cuDNN (CUDA Deep Neural Network Library)</strong>: A GPU-accelerated library of primitives for deep neural networks.</p>
<p><strong>Curriculum Learning</strong>: A machine learning training strategy where a model is trained on easier tasks or data first, and then gradually exposed to more complex ones.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="d">D<a href="#d" class="hash-link" aria-label="Direct link to D" title="Direct link to D" translate="no">​</a></h2>
<p><strong>DART (Dynamic Animation and Robotics Toolkit)</strong>: A physics engine optimized for robotics, known for simulating complex articulated bodies and contact dynamics, supported by Gazebo.</p>
<p><strong>DDS (Data Distribution Service)</strong>: An open international standard for publish-subscribe data exchange in distributed real-time systems, forming the communication backbone of ROS 2.</p>
<p><strong>Deep Learning</strong>: A subset of machine learning that uses artificial neural networks with multiple layers (deep neural networks) to learn from data.</p>
<p><strong>Depth Camera</strong>: A camera that captures distance information to objects in its field of view, in addition to color (e.g., Intel RealSense).</p>
<p><strong>Denavit-Hartenberg (DH) Parameters</strong>: A standard convention used to define the spatial relationship between adjacent rigid bodies in a kinematic chain.</p>
<p><strong>Deployment</strong>: The process of making a trained model or software application available for use in a target environment (e.g., on a robot or a cloud server).</p>
<p><strong>Dexterity</strong>: The robot&#x27;s ability to perform complex manipulation tasks with precision and skill.</p>
<p><strong>Dialogue State</strong>: The current understanding of a conversation, including user intent, extracted entities, and conversation history.</p>
<p><strong>Docusaurus</strong>: An open-source static site generator for building documentation websites, particularly popular for open-source projects.</p>
<p><strong>Domain Randomization</strong>: A technique used in simulation where non-essential parameters of the simulation are varied to improve the generalization of models trained on synthetic data to the real world.</p>
<p><strong>Dynamics</strong>: The study of motion and its causes (forces, torques). In robotics, it relates forces and torques to acceleration.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="e">E<a href="#e" class="hash-link" aria-label="Direct link to E" title="Direct link to E" translate="no">​</a></h2>
<p><strong>Edge AI</strong>: Artificial intelligence algorithms processed on a local device (e.g., Jetson) rather than in the cloud.</p>
<p><strong>Embodied AI</strong>: AI systems that interact with the physical world through a physical body, sensors, and actuators.</p>
<p><strong>End-effector</strong>: The part of a robotic arm that interacts with the environment (e.g., gripper, tool).</p>
<p><strong>Environment</strong>: In Reinforcement Learning, the context in which an agent operates, providing observations and rewards.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="f">F<a href="#f" class="hash-link" aria-label="Direct link to F" title="Direct link to F" translate="no">​</a></h2>
<p><strong>FK (Forward Kinematics)</strong>: The process of calculating the position and orientation of a robot&#x27;s end-effector given its joint angles.</p>
<p><strong>Force Control</strong>: A robot control strategy where the robot&#x27;s end-effector applies a desired force to an object or surface.</p>
<p><strong>Frontmatter</strong>: Metadata block at the beginning of a Markdown file (e.g., in Docusaurus) written in YAML, containing information like title, description, and keywords.</p>
<p><strong>Functional Requirements</strong>: Specific capabilities that a system must provide to its users.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="g">G<a href="#g" class="hash-link" aria-label="Direct link to G" title="Direct link to G" translate="no">​</a></h2>
<p><strong>Gait Generation</strong>: The process of creating the sequence of joint movements that result in a walking pattern for a legged robot.</p>
<p><strong>Gazebo</strong>: A popular 3D robotics simulator that allows for accurate simulation of robots, sensors, and environments.</p>
<p><strong>Gesture Recognition</strong>: The process of identifying human gestures (e.g., hand movements, body posture) through visual analysis.</p>
<p><strong>GitHub Pages</strong>: A free static site hosting service provided by GitHub, integrated with Git repositories.</p>
<p><strong>Global Planner</strong>: In navigation, an algorithm that computes a high-level, collision-free path from the robot&#x27;s start to its goal across the entire environment.</p>
<p><strong>GPT (Generative Pre-trained Transformer)</strong>: A family of large language models developed by OpenAI, capable of generating human-like text and understanding context.</p>
<p><strong>GPU (Graphics Processing Unit)</strong>: A specialized electronic circuit designed to rapidly manipulate and alter memory to accelerate the creation of images, often used for AI computations.</p>
<p><strong>Grasping</strong>: The action of a robot hand or gripper closing around an object to hold it.</p>
<p><strong>Ground Truth</strong>: The accurate, factual data used for training and evaluating machine learning models, often perfectly generated in simulation for synthetic data.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="h">H<a href="#h" class="hash-link" aria-label="Direct link to H" title="Direct link to H" translate="no">​</a></h2>
<p><strong>Hardware Tier</strong>: A categorization of recommended physical hardware setups (e.g., Workstation, Edge Kit, Robots) with varying performance and cost.</p>
<p><strong>HRI (Human-Robot Interaction)</strong>: The study of how humans and robots interact with each other, focusing on designing intuitive and effective interfaces.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="i">I<a href="#i" class="hash-link" aria-label="Direct link to I" title="Direct link to I" translate="no">​</a></h2>
<p><strong>IK (Inverse Kinematics)</strong>: The process of calculating the joint angles required for a robot&#x27;s end-effector to reach a desired position and orientation.</p>
<p><strong>IMU (Inertial Measurement Unit)</strong>: A sensor that measures a body&#x27;s specific force, angular rate, and sometimes the magnetic field surrounding the body, used to calculate orientation and velocity.</p>
<p><strong>Inertia Tensor</strong>: A mathematical quantity that describes an object&#x27;s resistance to rotational motion.</p>
<p><strong>Intent Extraction</strong>: The process of identifying the specific purpose or goal behind a natural language utterance.</p>
<p><strong>Integration Testing</strong>: Testing performed to ensure that different modules or components of a software application or robotic system function correctly together.</p>
<p><strong>Isaac Gym</strong>: A high-performance physics simulation environment by NVIDIA for training RL agents in robotics, leveraging GPU parallelism.</p>
<p><strong>Isaac Lab</strong>: The successor to Isaac Gym, offering advanced features for RL in robotics.</p>
<p><strong>Isaac ROS</strong>: A collection of hardware-accelerated ROS 2 packages leveraging NVIDIA GPUs for high-performance robotics perception and AI processing.</p>
<p><strong>Isaac SDK</strong>: A software development kit by NVIDIA providing algorithms and tools for robot development.</p>
<p><strong>Isaac Sim</strong>: A scalable robotics simulation application built on NVIDIA Omniverse, offering photorealistic rendering and synthetic data generation.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="j">J<a href="#j" class="hash-link" aria-label="Direct link to J" title="Direct link to J" translate="no">​</a></h2>
<p><strong>Jetson Orin Nano</strong>: An NVIDIA embedded computing module for edge AI applications, commonly used in robotics.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="l">L<a href="#l" class="hash-link" aria-label="Direct link to L" title="Direct link to L" translate="no">​</a></h2>
<p><strong>Language Model</strong>: A statistical model that determines the probability of a sequence of words, used in Natural Language Processing.</p>
<p><strong>Launch File</strong>: A configuration file (typically Python in ROS 2) used to start and manage multiple ROS 2 nodes and their parameters.</p>
<p><strong>LiDAR (Light Detection and Ranging)</strong>: A remote sensing method that uses pulsed laser light to measure distances, often used for creating 3D maps.</p>
<p><strong>LIPM (Linear Inverted Pendulum Model)</strong>: A simplified dynamic model used in bipedal locomotion control to approximate the robot&#x27;s center of mass motion.</p>
<p><strong>LLM (Large Language Model)</strong>: A type of artificial intelligence program that can generate and understand human language, trained on vast amounts of text data.</p>
<p><strong>Localization</strong>: The process of determining a robot&#x27;s position and orientation within a map.</p>
<p><strong>Locomotion</strong>: The act or power of moving from place to place. In robotics, specifically how a robot moves (e.g., wheeled, legged, bipedal).</p>
<p><strong>LTS (Long-Term Support)</strong>: A software release cycle indicating extended support and maintenance, providing greater stability.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="m">M<a href="#m" class="hash-link" aria-label="Direct link to M" title="Direct link to M" translate="no">​</a></h2>
<p><strong>Manipulation</strong>: The act of a robot interacting with objects in its environment, typically involving grasping, moving, and placing.</p>
<p><strong>MDX</strong>: Markdown with JSX, allowing you to embed React components directly within your Markdown content. Used by Docusaurus.</p>
<p><strong>MediaPipe</strong>: An open-source framework by Google for building multi-modal machine learning pipelines, often used for real-time human pose and gesture recognition.</p>
<p><strong>Mermaid</strong>: A Markdown-inspired tool for generating diagrams and flowcharts from text definitions.</p>
<p><strong>Microphone Array</strong>: A group of microphones working together to capture sound, often used for beamforming and noise reduction in robotics.</p>
<p><strong>Modeling Errors</strong>: Discrepancies between a simulation model and the real-world system it represents.</p>
<p><strong>Motion Planning</strong>: The process of finding a sequence of valid configurations that moves a robot from a start state to a goal state while avoiding obstacles.</p>
<p><strong>MoveIt 2</strong>: A ROS 2 package that provides motion planning capabilities for robotic manipulators.</p>
<p><strong>Multi-modal Fusion</strong>: The process of combining information from multiple sensory modalities (e.g., vision, speech, touch) to improve perception and understanding.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="n">N<a href="#n" class="hash-link" aria-label="Direct link to N" title="Direct link to N" translate="no">​</a></h2>
<p><strong>Nav2 (Navigation2)</strong>: The standard navigation framework in ROS 2, providing tools for autonomous mobile robot navigation.</p>
<p><strong>Neural Network</strong>: A type of machine learning algorithm inspired by the structure and function of the human brain.</p>
<p><strong>Node</strong>: An executable in ROS 2 that performs computation (e.g., sensor driver, control algorithm).</p>
<p><strong>Node Graph</strong>: A visual representation of the ROS 2 nodes and their connections (topics, services, actions).</p>
<p><strong>Noise Model</strong>: A mathematical model used in simulation to replicate the imperfections and variability of real-world sensor measurements.</p>
<p><strong>NPM (Node Package Manager)</strong>: The default package manager for Node.js.</p>
<p><strong>NLU (Natural Language Understanding)</strong>: A subfield of natural language processing that focuses on enabling computers to understand the meaning of human language.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="o">O<a href="#o" class="hash-link" aria-label="Direct link to O" title="Direct link to O" translate="no">​</a></h2>
<p><strong>Object Detection</strong>: The computer vision task of identifying the presence, location, and class of objects within an image or video.</p>
<p><strong>Occupancy Grid Map</strong>: A 2D grid representation of an environment where each cell indicates the probability of being occupied by an obstacle.</p>
<p><strong>ODE (Open Dynamics Engine)</strong>: A high-performance library for simulating articulated rigid body dynamics, commonly used in Gazebo.</p>
<p><strong>Omniverse</strong>: A platform developed by NVIDIA for connecting and building 3D workflows, on which Isaac Sim is based.</p>
<p><strong>ONNX (Open Neural Network Exchange)</strong>: An open standard format for representing machine learning models, enabling interoperability between different frameworks.</p>
<p><strong>OpenPose</strong>: An open-source real-time multi-person system to detect human body, hand, facial, and foot keypoints on images and videos.</p>
<p><strong>Optimization-based Methods</strong>: In gait generation, algorithms that find gaits by minimizing cost functions (e.g., energy consumption) or maximizing stability.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="p">P<a href="#p" class="hash-link" aria-label="Direct link to P" title="Direct link to P" translate="no">​</a></h2>
<p><strong>Package</strong>: The fundamental unit of software organization in ROS 2, containing nodes, libraries, and other resources.</p>
<p><strong>package.xml</strong>: An XML file in a ROS 2 package that contains metadata like name, version, dependencies, and maintainer information.</p>
<p><strong>Parameters</strong>: Configuration values for ROS 2 nodes that can be set at runtime.</p>
<p><strong>Path Planning</strong>: The process of finding a sequence of configurations (a path) for a robot to move from a start location to a goal location.</p>
<p><strong>Perception</strong>: The process by which robots interpret sensory information to understand their environment.</p>
<p><strong>Physical AI</strong>: See Embodied AI.</p>
<p><strong>Physics Engine</strong>: Software that simulates the behavior of physical systems, including gravity, collisions, and forces.</p>
<p><strong>Policy</strong>: In Reinforcement Learning, the strategy that an agent uses to determine its actions in an environment.</p>
<p><strong>Pose</strong>: A combination of position and orientation in 3D space.</p>
<p><strong>PPO (Proximal Policy Optimization)</strong>: A popular Reinforcement Learning algorithm known for its stability and good performance.</p>
<p><strong>Prism.js</strong>: A lightweight, extensible syntax highlighter used by Docusaurus.</p>
<p><strong>Prompt Engineering</strong>: The art and science of crafting effective prompts to guide large language models to produce desired outputs.</p>
<p><strong>Proprioception</strong>: The sense of the relative position of neighboring parts of the body and strength of effort being employed in movement. Robot joint encoders provide proprioceptive feedback.</p>
<p><strong>PyBullet</strong>: A Python module for the Bullet Physics SDK, providing fast and accurate physics simulation, kinematics, and RL integration.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="q">Q<a href="#q" class="hash-link" aria-label="Direct link to Q" title="Direct link to Q" translate="no">​</a></h2>
<p><strong>QoS (Quality of Service)</strong>: A set of policies in ROS 2 that configure the communication behavior between nodes (e.g., reliability, history, liveliness).</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="r">R<a href="#r" class="hash-link" aria-label="Direct link to R" title="Direct link to R" translate="no">​</a></h2>
<p><strong>rclpy</strong>: The Python client library for ROS 2, enabling Python code to interact with the ROS 2 ecosystem.</p>
<p><strong>Reality Gap</strong>: The discrepancy between the performance of a robot or AI model in simulation versus its performance in the real world.</p>
<p><strong>RealSense D435i</strong>: An Intel depth camera that provides RGB and depth information, commonly used in robotics.</p>
<p><strong>Reinforcement Learning (RL)</strong>: A type of machine learning where an agent learns to make decisions by performing actions in an environment to maximize a cumulative reward.</p>
<p><strong>ReSpeaker</strong>: A series of microphone arrays designed for AI and voice applications, often used in robotics.</p>
<p><strong>Replicator</strong>: NVIDIA Isaac Replicator is a powerful SDK within Isaac Sim for programmatic generation of synthetic datasets.</p>
<p><strong>Robotics</strong>: The interdisciplinary branch of engineering and science that deals with the design, construction, operation, and use of robots.</p>
<p><strong>ROS 2 (Robot Operating System 2)</strong>: An open-source, meta-operating system for robots, providing a standardized framework for building robotic applications.</p>
<p><strong>ROS-TCP-Connector</strong>: A Unity package that enables communication between Unity applications and ROS 2 systems.</p>
<p><strong>rqt_console</strong>: A ROS 2 GUI tool for viewing and filtering log messages from ROS 2 nodes.</p>
<p><strong>rqt_graph</strong>: A ROS 2 GUI tool for visualizing the ROS 2 computation graph (nodes and their connections).</p>
<p><strong>RViz2</strong>: The 3D visualization tool for ROS 2, used to visualize robot models, sensor data, and navigation plans.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="s">S<a href="#s" class="hash-link" aria-label="Direct link to S" title="Direct link to S" translate="no">​</a></h2>
<p><strong>SAC (Soft Actor-Critic)</strong>: An off-policy Reinforcement Learning algorithm known for its stability and sample efficiency.</p>
<p><strong>SDF (Simulation Description Format)</strong>: An XML format used to describe robots, environments, and other simulation properties in Gazebo.</p>
<p><strong>Semantic Segmentation</strong>: A computer vision task that involves classifying each pixel in an image to a corresponding class (e.g., identifying all pixels belonging to a &quot;car&quot;).</p>
<p><strong>Sensor</strong>: A device that detects and responds to some type of input from the physical environment (e.g., camera, LiDAR, IMU).</p>
<p><strong>Serial Chain</strong>: A type of robotic manipulator where links are connected end-to-end in a chain, with each joint connecting only two links.</p>
<p><strong>Service</strong>: In ROS 2, a communication mechanism that implements a request/response pattern for synchronous, blocking calls between nodes.</p>
<p><strong>setup.py</strong>: A Python script used by <code>setuptools</code> to configure the build and distribution of Python packages, including ROS 2 Python packages.</p>
<p><strong>Sim-to-Real Transfer</strong>: The process of successfully deploying an AI model or control policy trained in simulation to a real-world robot.</p>
<p><strong>SLAM (Simultaneous Localization and Mapping)</strong>: The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent&#x27;s location within it.</p>
<p><strong>Smac Planner</strong>: A motion planner in Nav2 that can generate kinematically feasible paths for various robot types.</p>
<p><strong>Speech Recognition</strong>: See ASR.</p>
<p><strong>Support Polygon</strong>: The area on the ground defined by the contact points of a legged robot&#x27;s feet. The ZMP must remain within this polygon for static balance.</p>
<p><strong>Synthetic Data</strong>: Data generated by computer simulations or algorithms, often used to train machine learning models.</p>
<p><strong>System Identification</strong>: The process of using experimental data to build or refine a mathematical model of a system&#x27;s dynamics.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="t">T<a href="#t" class="hash-link" aria-label="Direct link to T" title="Direct link to T" translate="no">​</a></h2>
<p><strong>Task Decomposition</strong>: Breaking down a complex high-level task into a sequence of smaller, manageable sub-tasks.</p>
<p><strong>TF-IDF (Term Frequency-Inverse Document Frequency)</strong>: A statistical measure used to evaluate how important a word is to a document in a collection or corpus.</p>
<p><strong>TF2 (Transformation Library 2)</strong>: A ROS 2 library that keeps track of multiple coordinate frames and allows for transformations between them.</p>
<p><strong>TensorRT</strong>: NVIDIA&#x27;s SDK for high-performance deep learning inference.</p>
<p><strong>Topic</strong>: In ROS 2, a named bus over which nodes exchange messages using a publish-subscribe pattern.</p>
<p><strong>TRAC-IK</strong>: An IK solver optimized for speed and collision avoidance for redundant robotic manipulators.</p>
<p><strong>Transformers Library</strong>: Hugging Face&#x27;s open-source library providing state-of-the-art pre-trained models for Natural Language Processing (NLP).</p>
<p><strong>Triangulation</strong>: A method used to determine the 3D position of a point by measuring angles or distances from two or more known positions.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="u">U<a href="#u" class="hash-link" aria-label="Direct link to U" title="Direct link to U" translate="no">​</a></h2>
<p><strong>Ubuntu 22.04 LTS</strong>: A Long Term Support (LTS) release of the Ubuntu Linux operating system, commonly used for ROS 2 development.</p>
<p><strong>Underactuation</strong>: A design principle in robotics where fewer actuators control more degrees of freedom, often leveraging mechanical coupling.</p>
<p><strong>Unitree Robotics</strong>: A company known for its legged robots (e.g., Go2, G1).</p>
<p><strong>Unity</strong>: A popular cross-platform game engine and real-time 3D development platform used for high-fidelity robotics simulation.</p>
<p><strong>URDF (Unified Robot Description Format)</strong>: An XML format used in ROS to describe the physical characteristics of a robot.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="v">V<a href="#v" class="hash-link" aria-label="Direct link to V" title="Direct link to V" translate="no">​</a></h2>
<p><strong>VS Code (Visual Studio Code)</strong>: A popular free source-code editor made by Microsoft for Windows, Linux and macOS.</p>
<p><strong>VSLAM (Visual Simultaneous Localization and Mapping)</strong>: A type of SLAM that uses cameras as its primary sensor for both localization and mapping.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="w">W<a href="#w" class="hash-link" aria-label="Direct link to W" title="Direct link to W" translate="no">​</a></h2>
<p><strong>Whisper</strong>: OpenAI&#x27;s general-purpose speech recognition model.</p>
<p><strong>Word Embedding</strong>: A representation of a word in a multi-dimensional space, where words with similar meanings are close together.</p>
<p><strong>Workspace</strong>: In ROS 2, a directory where you develop, build, and install your ROS 2 packages.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="x">X<a href="#x" class="hash-link" aria-label="Direct link to X" title="Direct link to X" translate="no">​</a></h2>
<p><strong>Xacro (XML Macros)</strong>: An XML macro language used with URDF to parameterize and modularize robot descriptions.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="y">Y<a href="#y" class="hash-link" aria-label="Direct link to Y" title="Direct link to Y" translate="no">​</a></h2>
<p><strong>YAML (YAML Ain&#x27;t Markup Language)</strong>: A human-friendly data serialization standard often used for configuration files in ROS 2.</p>
<p><strong>YOLO (You Only Look Once)</strong>: A popular real-time object detection algorithm.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="z">Z<a href="#z" class="hash-link" aria-label="Direct link to Z" title="Direct link to Z" translate="no">​</a></h2>
<p><strong>ZMP (Zero Moment Point)</strong>: A crucial concept in bipedal locomotion; the point on the ground where the net moment of all forces acting on the robot is zero, indicating balance.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/appendices/glossary.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/appendices/troubleshooting"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Troubleshooting</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/appendices/resources"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Resources</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#a" class="table-of-contents__link toc-highlight">A</a></li><li><a href="#b" class="table-of-contents__link toc-highlight">B</a></li><li><a href="#c" class="table-of-contents__link toc-highlight">C</a></li><li><a href="#d" class="table-of-contents__link toc-highlight">D</a></li><li><a href="#e" class="table-of-contents__link toc-highlight">E</a></li><li><a href="#f" class="table-of-contents__link toc-highlight">F</a></li><li><a href="#g" class="table-of-contents__link toc-highlight">G</a></li><li><a href="#h" class="table-of-contents__link toc-highlight">H</a></li><li><a href="#i" class="table-of-contents__link toc-highlight">I</a></li><li><a href="#j" class="table-of-contents__link toc-highlight">J</a></li><li><a href="#l" class="table-of-contents__link toc-highlight">L</a></li><li><a href="#m" class="table-of-contents__link toc-highlight">M</a></li><li><a href="#n" class="table-of-contents__link toc-highlight">N</a></li><li><a href="#o" class="table-of-contents__link toc-highlight">O</a></li><li><a href="#p" class="table-of-contents__link toc-highlight">P</a></li><li><a href="#q" class="table-of-contents__link toc-highlight">Q</a></li><li><a href="#r" class="table-of-contents__link toc-highlight">R</a></li><li><a href="#s" class="table-of-contents__link toc-highlight">S</a></li><li><a href="#t" class="table-of-contents__link toc-highlight">T</a></li><li><a href="#u" class="table-of-contents__link toc-highlight">U</a></li><li><a href="#v" class="table-of-contents__link toc-highlight">V</a></li><li><a href="#w" class="table-of-contents__link toc-highlight">W</a></li><li><a href="#x" class="table-of-contents__link toc-highlight">X</a></li><li><a href="#y" class="table-of-contents__link toc-highlight">Y</a></li><li><a href="#z" class="table-of-contents__link toc-highlight">Z</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/Physical-AI-Humanoid-Robotics-Textbook/docs/intro/what-is-physical-ai">Book</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://twitter.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Physical AI & Humanoid Robotics Book. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>