"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[9349],{8453:(e,n,i)=>{i.d(n,{R:()=>s,x:()=>t});var a=i(6540);const o={},r=a.createContext(o);function s(e){const n=a.useContext(r);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),a.createElement(r.Provider,{value:n},e.children)}},9117:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>t,default:()=>d,frontMatter:()=>s,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"module-2-simulation/sensor-simulation","title":"Sensor Simulation (LiDAR, Depth Cameras, IMUs)","description":"Sensor plugins in Gazebo, LiDAR setup and configuration, Depth camera (RealSense) simulation, IMU implementation, Publishing to ROS 2 topics, Noise models.","source":"@site/docs/module-2-simulation/sensor-simulation.mdx","sourceDirName":"module-2-simulation","slug":"/module-2-simulation/sensor-simulation","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/docs/module-2-simulation/sensor-simulation","draft":false,"unlisted":false,"editUrl":"https://github.com/Darakhshan08/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-2-simulation/sensor-simulation.mdx","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"sensor-simulation","title":"Sensor Simulation (LiDAR, Depth Cameras, IMUs)","sidebar_label":"Sensor Simulation","sidebar_position":4,"description":"Sensor plugins in Gazebo, LiDAR setup and configuration, Depth camera (RealSense) simulation, IMU implementation, Publishing to ROS 2 topics, Noise models.","keywords":["gazebo","sensors","lidar","depth-camera","imu","ros2","noise-models"]},"sidebar":"tutorialSidebar","previous":{"title":"Physics Simulation","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/docs/module-2-simulation/physics-simulation"},"next":{"title":"HRI in Simulation","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/docs/module-2-simulation/hri-simulation"}}');var o=i(4848),r=i(8453);const s={id:"sensor-simulation",title:"Sensor Simulation (LiDAR, Depth Cameras, IMUs)",sidebar_label:"Sensor Simulation",sidebar_position:4,description:"Sensor plugins in Gazebo, LiDAR setup and configuration, Depth camera (RealSense) simulation, IMU implementation, Publishing to ROS 2 topics, Noise models.",keywords:["gazebo","sensors","lidar","depth-camera","imu","ros2","noise-models"]},t="Sensor Simulation (LiDAR, Depth Cameras, IMUs)",l={},c=[{value:"Sensor Plugins in Gazebo",id:"sensor-plugins-in-gazebo",level:2},{value:"LiDAR Setup and Configuration",id:"lidar-setup-and-configuration",level:2},{value:"Example: LiDAR Sensor Plugin Configuration",id:"example-lidar-sensor-plugin-configuration",level:3},{value:"Depth Camera (RealSense) Simulation",id:"depth-camera-realsense-simulation",level:2},{value:"Example: Depth Camera Sensor Plugin Configuration",id:"example-depth-camera-sensor-plugin-configuration",level:3},{value:"IMU Implementation",id:"imu-implementation",level:2},{value:"Example: IMU Sensor Plugin Configuration",id:"example-imu-sensor-plugin-configuration",level:3},{value:"Publishing to ROS 2 Topics",id:"publishing-to-ros-2-topics",level:2},{value:"Noise Models",id:"noise-models",level:2},{value:"Example: Adding Gaussian Noise to a Camera Sensor",id:"example-adding-gaussian-noise-to-a-camera-sensor",level:3}];function m(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"sensor-simulation-lidar-depth-cameras-imus",children:"Sensor Simulation (LiDAR, Depth Cameras, IMUs)"})}),"\n",(0,o.jsx)(n.p,{children:"Accurate sensor simulation is paramount for developing and testing robotic perception algorithms. Gazebo provides a rich set of sensor plugins that allow you to simulate various types of sensors, generating realistic data streams that can be published to ROS 2 topics."}),"\n",(0,o.jsx)(n.h2,{id:"sensor-plugins-in-gazebo",children:"Sensor Plugins in Gazebo"}),"\n",(0,o.jsx)(n.p,{children:"Gazebo's sensor plugins are dynamic libraries that can be attached to a link within your robot model or directly to the world. They simulate the physical behavior of a sensor and often publish data in standard ROS 2 message formats."}),"\n",(0,o.jsx)(n.p,{children:"Common sensor plugins include:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.code,{children:"libgazebo_ros_laser.so"})}),": For LiDAR (Laser Imaging, Detection, and Ranging) sensors."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.code,{children:"libgazebo_ros_camera.so"})})," / ",(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.code,{children:"libgazebo_ros_depth_camera.so"})}),": For RGB cameras and depth cameras."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.code,{children:"libgazebo_ros_imu.so"})}),": For Inertial Measurement Units."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.code,{children:"libgazebo_ros_force_torque.so"})}),": For force/torque sensors."]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"lidar-setup-and-configuration",children:"LiDAR Setup and Configuration"}),"\n",(0,o.jsx)(n.p,{children:"LiDAR sensors measure distances to objects by emitting laser pulses and detecting their reflections. They are crucial for mapping, navigation, and obstacle avoidance."}),"\n",(0,o.jsx)(n.h3,{id:"example-lidar-sensor-plugin-configuration",children:"Example: LiDAR Sensor Plugin Configuration"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-xml",children:'<link name="hokuyo_link">\r\n  <inertial>...</inertial>\r\n  <visual>...</visual>\r\n  <collision>...</collision>\r\n</link>\r\n\r\n<joint name="hokuyo_joint" type="fixed">\r\n  <parent link="base_link"/>\r\n  <child link="hokuyo_link"/>\r\n  <origin xyz="0 0 0.1" rpy="0 0 0"/>\r\n</joint>\r\n\r\n<gazebo reference="hokuyo_link">\r\n  <sensor name="laser_sensor" type="ray">\r\n    <pose>0 0 0 0 0 0</pose>\r\n    <visualize>true</visualize>\r\n    <update_rate>30</update_rate>\r\n    <ray>\r\n      <scan>\r\n        <horizontal>\r\n          <samples>720</samples>\r\n          <resolution>1</resolution>\r\n          <min_angle>-1.5708</min_angle>\r\n          <max_angle>1.5708</max_angle>\r\n        </horizontal>\r\n        <vertical>\r\n          <samples>1</samples>\r\n          <resolution>1</resolution>\r\n          <min_angle>0</min_angle>\r\n          <max_angle>0</max_angle>\r\n        </vertical>\r\n      </scan>\r\n      <range>\r\n        <min>0.1</min>\r\n        <max>10.0</max>\r\n        <resolution>0.01</resolution>\r\n      </range>\r\n    </ray>\r\n    <plugin name="gazebo_ros_laser_controller" filename="libgazebo_ros_laser.so">\r\n      <topicName>/scan</topicName>\r\n      <frameName>hokuyo_link</frameName>\r\n    </plugin>\r\n  </sensor>\r\n</gazebo>\n'})}),"\n",(0,o.jsxs)(n.p,{children:["This configuration creates a 2D LiDAR sensor attached to ",(0,o.jsx)(n.code,{children:"hokuyo_link"}),", publishing ",(0,o.jsx)(n.code,{children:"sensor_msgs/LaserScan"})," messages on the ",(0,o.jsx)(n.code,{children:"/scan"})," ROS 2 topic."]}),"\n",(0,o.jsx)(n.h2,{id:"depth-camera-realsense-simulation",children:"Depth Camera (RealSense) Simulation"}),"\n",(0,o.jsx)(n.p,{children:"Depth cameras, like the Intel RealSense D435i, provide both RGB images and depth information, enabling 3D perception."}),"\n",(0,o.jsx)(n.h3,{id:"example-depth-camera-sensor-plugin-configuration",children:"Example: Depth Camera Sensor Plugin Configuration"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-xml",children:'<link name="camera_link">\r\n  <inertial>...</inertial>\r\n  <visual>...</visual>\r\n  <collision>...</collision>\r\n</link>\r\n\r\n<joint name="camera_joint" type="fixed">\r\n  <parent link="base_link"/>\r\n  <child link="camera_link"/>\r\n  <origin xyz="0.1 0 0.2" rpy="0 0 0"/>\r\n</joint>\r\n\r\n<gazebo reference="camera_link">\r\n  <sensor name="depth_camera_sensor" type="depth_camera">\r\n    <pose>0 0 0 0 0 0</pose>\r\n    <visualize>true</visualize>\r\n    <update_rate>30</update_rate>\r\n    <camera>\r\n      <horizontal_fov>1.089</horizontal_fov> \x3c!-- ~60 deg --\x3e\r\n      <image>\r\n        <width>640</width>\r\n        <height>480</height>\r\n        <format>R8G8B8</format>\r\n      </image>\r\n      <clip>\r\n        <near>0.05</near>\r\n        <far>5</far>\r\n      </clip>\r\n    </camera>\r\n    <plugin name="camera_controller" filename="libgazebo_ros_depth_camera.so">\r\n      <baseline>0.0</baseline>\r\n      <alwaysOn>true</alwaysOn>\r\n      <imageTopicName>color/image_raw</imageTopicName>\r\n      <cameraInfoTopicName>color/camera_info</cameraInfoTopicName>\r\n      <depthImageTopicName>depth/image_raw</depthImageTopicName>\r\n      <depthImageInfoTopicName>depth/camera_info</depthImageInfoTopicName>\r\n      <pointCloudTopicName>depth/color/points</pointCloudTopicName>\r\n      <pointCloudCutoff>0.4</pointCloudCutoff>\r\n      <pointCloudCutoffMax>5.0</pointCloudCutoffMax>\r\n      <frameName>camera_link</frameName>\r\n      <hackBaseline>0.07</hackBaseline>\r\n      <distortionK1>0.0</distortionK1>\r\n      <distortionK2>0.0</distortionK2>\r\n      <distortionK3>0.0</distortionK3>\r\n      <distortionT1>0.0</distortionT1>\r\n      <distortionT2>0.0</distortionT2>\r\n      <Cx>320.5</Cx>\r\n      <Cy>240.5</Cy>\r\n      <focalLength>554.25</focalLength>\r\n      <hackBaseline>0.0</hackBaseline>\r\n    </plugin>\r\n  </sensor>\r\n</gazebo>\n'})}),"\n",(0,o.jsx)(n.p,{children:"This simulates a depth camera publishing RGB images, depth images, camera info, and point clouds to ROS 2 topics."}),"\n",(0,o.jsx)(n.h2,{id:"imu-implementation",children:"IMU Implementation"}),"\n",(0,o.jsx)(n.p,{children:"An Inertial Measurement Unit (IMU) provides linear acceleration and angular velocity data, essential for robot localization, stabilization, and control."}),"\n",(0,o.jsx)(n.h3,{id:"example-imu-sensor-plugin-configuration",children:"Example: IMU Sensor Plugin Configuration"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-xml",children:'<link name="imu_link">\r\n  <inertial>...</inertial>\r\n  <visual>...</visual>\r\n  <collision>...</collision>\r\n</link>\r\n\r\n<joint name="imu_joint" type="fixed">\r\n  <parent link="base_link"/>\r\n  <child link="imu_link"/>\r\n  <origin xyz="0 0 0" rpy="0 0 0"/>\r\n</joint>\r\n\r\n<gazebo reference="imu_link">\r\n  <sensor name="imu_sensor" type="imu">\r\n    <always_on>true</always_on>\r\n    <update_rate>100</update_rate>\r\n    <plugin name="imu_plugin" filename="libgazebo_ros_imu_sensor.so">\r\n      <ros>\r\n        <namespace>imu</namespace>\r\n        <argument>--ros-args -r imu:=imu_data</argument>\r\n      </ros>\r\n      <topicName>imu_data</topicName>\r\n      <frameName>imu_link</frameName>\r\n      <initialOrientationAsReference>false</initialOrientationAsReference>\r\n    </plugin>\r\n  </sensor>\r\n</gazebo>\n'})}),"\n",(0,o.jsxs)(n.p,{children:["This configures an IMU sensor publishing ",(0,o.jsx)(n.code,{children:"sensor_msgs/Imu"})," messages on the ",(0,o.jsx)(n.code,{children:"/imu_data"})," topic."]}),"\n",(0,o.jsx)(n.h2,{id:"publishing-to-ros-2-topics",children:"Publishing to ROS 2 Topics"}),"\n",(0,o.jsx)(n.p,{children:"All of the above sensor plugins are configured to publish their simulated data directly to ROS 2 topics, typically in standard ROS 2 message formats. You can inspect these topics using:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"ros2 topic list\r\nros2 topic echo /scan\r\nros2 topic echo /imu_data\n"})}),"\n",(0,o.jsx)(n.h2,{id:"noise-models",children:"Noise Models"}),"\n",(0,o.jsx)(n.p,{children:"Real-world sensors are imperfect and introduce noise into their measurements. Gazebo allows you to model various types of noise (Gaussian, Gaussian with bias, etc.) to make simulations more realistic. This is crucial for testing the robustness of your perception algorithms."}),"\n",(0,o.jsx)(n.h3,{id:"example-adding-gaussian-noise-to-a-camera-sensor",children:"Example: Adding Gaussian Noise to a Camera Sensor"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-xml",children:'<sensor name="camera" type="camera">\r\n  \x3c!-- ... camera configuration ... --\x3e\r\n  <camera>\r\n    \x3c!-- ... camera intrinsic parameters ... --\x3e\r\n    <noise>\r\n      <type>gaussian</type>\r\n      <mean>0.0</mean>\r\n      <stddev>0.007</stddev>\r\n    </noise>\r\n  </camera>\r\n</sensor>\n'})}),"\n",(0,o.jsx)(n.p,{children:"Noise models can be applied to various sensor types to simulate real-world sensor imperfections."})]})}function d(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(m,{...e})}):m(e)}}}]);